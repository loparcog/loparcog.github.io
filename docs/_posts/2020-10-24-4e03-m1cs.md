---
layout: post
title:  "4E03 - Midterm 1 Cheat Sheet"
date:   2020-10-24 10:00:00 -0400
categories: 4E03
---

COVERS LECTURES 0-15

Probability
===
NOTE: Skipping the basic probability work along with independent events since those were reviewed back for 3Y03, just going over main things I think would be useful

Random Variables
- A random variable *X* (capital letters) is a real-valued function of the outcome of an experiment
- Can be discrete or continuous
- We will use the **cumulative distribution function** (distribution, cdf) to define probabilities of events, defined as $F_X(x)$:  
$$F_X(x) = P(X \leq x)$$
    - We can just use $F(x)$ is the variable is clear
- **Continuous Random Variables**
    - For quantities that take on values on a continuum, involving real numbers, ie. time
    - $F(x)$ is continuous
    - The density function is given as:  
    $$f_X(x) = \frac{dF_X(x)}{dx}$$  
    $$P(a \leq X \leq b) = F_X(b) - F_X(a) = \int_a^b f_X(x) dx$$  
    $$\int_{-\inf}^{\inf} f_X(x) dx = 1$$
- **Discrete Random Variables**
    - For discrete values, a range NOT containing real numbers
    - The **probability mass function** (pmf) gives the probability that a random variable equals a value:  
    $$p_X(i) = P(X = i)$$  
    $$P(j \lt X \leq k) = F_X(k) - F_X(j) = \sum_{j \lt i \leq k} p_X(i)$$  
    $$\sum_i p_X(i) = 1$$
- **Expected Value** (or mean) is given by the following equations for $E[X]$
    - Discrete:  
    $$E[X] = \sum_i ip_X(i)$$
    - Continuous:  
    $$E[X] = \int_{-\inf}^{\inf} xf_X(x) dx$$
- **Higher Moments** can compute the *k*th moment of a probability, given by the following equations for $E[X^k]$
    - Discrete:  
    $$E[X^k] = \sum_i i^kp_X(i)$$
    - Continuous:  
    $$E[X^k] = \int_{-\inf}^{\inf} x^kf_X(x) dx$$
    - Important ones are k=1 (mean) and k=2
- **Variance** measures the expected deviation from the mean (how spread out the distribution is)  
$$Var(X) = \sigma_X^2 = E[X^2] - (E[X])^2$$

Distributions
- **Geometric Distribution**
    - Where $q$ is the probability of success, $1-q$ is the probability of failure, and $p_X(k)$ is the probability that success first happens on the *k*th trial  
    $$p_X(k) = q(1-q)^{k-1}, k = 1, 2, ...$$
    $$E[X] = \frac{1}{q}$$  
    $$Var(X) = \frac{1-q}{q^2}$$
- **Poisson Distribution**
    - Has one parameter of rate, $\lambda$, ang has pmf:  
    $$p_X(k) = \frac{e^{-\lambda}\lambda^k}{k!}, k=0, 1, 2...$$  
    $$E[X] = Var(X) = \lambda$$  
    Also note the following property:  
    $$\sum_{k=0}^{\inf} e^{-\lambda}\frac{\lambda^k}{k!} = e^{-\lambda}e^{\lambda} = 1$$
- **Uniform Distribution**
    - Denoted by $U(a, b)$, random variable is equally likely to take values between a and b  
    $$f(x) = \{^{1/(b-a), a \leq x \leq b}_{0 \text{ otherwise}}$$  
    $$E[X] = \frac{a+b}{2}$$  
    $$Var(X) = \frac{(b-a)^2}{12}$$
- **Exponential Distribution**
    - One parameter, "rate" $\lambda$  
    $$f_X(x) = \{^{\lambda e^{-\lambda x}, x \geq 0}_{0, x \lt 0}$$  
    $$F_X(x) = \{^{1-e^{-\lambda x}, x \geq 0}_{0, x \lt 0}$$  
    $$E[X] = 1/\lambda$$  
    $$Var(X) = 1/\lambda^2$$
    - Also note, the **memoryless property** applies to this distribution. This states that the future is independent of the past, given the present

Performance Introduction
- **Throughput**: How many requests per unit time can the data centre handle?
- **Response Time**: How long is a job in the data centre (frim arrival to departure)?
- **Energy Consumption**: How much energy is the data centre consuming?
- **Reliability**: What is the likelihood of an outage in a given period of time?
- **Workload**: Average number of requests per time unit, likelihood of a "large" number of requests in a given time interval, etc.
- **Response Time**: Average response time, likelihood of a "long" response time, etc.
- Essentially, we want a model for how the data centre operates, capturing essential behaviour while being as *abstract* as possible

Markov Chains
===

Stochastic Models
- May want to capture how a system evolves, using *dependent* random variables, described by some dynamics
- Very simple model is the DTMC, used in...
    - User web page navigation
    - Cache contents and performance
    - Speech recognition
    - Machine learning
    - etc.
- This is also an example of a discrete-time system
- The *n*th "time point" corresponds to the *n*th page visited
- Natural for some settings, but continuous-time framework may be more suitable for others

Discrete-Time Markov Chains (DTMCs)
- A DTMC is a stochastic process $(X_n, n=0, 1, 2, ...)$, where $X_n$ denotes the state at (discrete) time step *n* and such that, $\forall n \geq 0, \forall i, j$ and $\forall i_0, ..., i_{n-1}$:  
$$P(X_n+1 = j | X_n=1, X_{n-1} = i_{n-1}, ..., X_0 = u_0)$$  
$$= P(X_{n+1} = j | X_n = i)$$  
$$= P_{ij}$$
- Last equality is a property known as **stationary**: statistics of process independent of time - $P_{ij}$ is independent of the time step and history
- "Chain" is used since states are "chained" togehter by transitions
- **Markovian Property**: The conditional distribution of any future state $X_{n+1}$, given past states $X_0, X_1, ..., X{n-1}$ and the present state $X_n$ is independent of past states, and **only** depends on the present state $X_n$
- **Transition Probability Matrix**: Associated with any DTMC is a matrix, *P*, whose *i*, *j* entry, $P_{ij}$, represents the probability of moving to state *j* from state *i*
    - *P* may have infinite dimensions, is square, and the rows of *P* should sum to one
    - Also, $P_{ii} \gt 0$ is possible

*n*-step Transition Probabilities
- Let $P^n = P * P ... P$, *n* copies of *P* multipled together
- $P_{ij}^n$: (i, j) entry of $P^n$
- Represents the probability of going from state *i* to *j* in *n* steps
- Calculated with the given probability:  
$$P_{ij}^n = \sum_{k=0}^{M-1} P_{ik}^{m-1} P{kj}$$
- We can also calculate the **limiting probabilities** with this. Let:  
$$\pi_j = \lim_{n \rightarrow \inf} P_{ij}^n$$
- $\pi_j$ represents the limiting probability that the DTMC is in state *j*. For an *M*-state DTMC, with states, 0, 1, ..., *M*-1:  
$$\pi = [\pi_0, \pi_1, ..., \pi_{M-1}]$$  
Also, there is the properties of  
$$\sum_{i=0}^{M-1} \pi_i = 1$$  
$$\pi_j \gt 0$$
- These values can be calculated with the equations:  
$$\pi P = \pi$$  
and  
$$\sum_{i=0}^{M-1} \pi_i = 1$$

Infinite State DTMCs
- Same results hold relating limiting and stationary distributions, only proofs are trickier (interchanging limits and infinite sums have to be done with more care)
- Main issue: Need to solve an infinite number of linear equations for an infinite number of unknowns
- Main case is where there is a probability of *r* for going up a state, a probability of *s* of going down a state, and *1-r-s* of staying in the same state
- If we use $\rho = r/s$, then we can get the equation:  
$$\pi_n = \rho^n(1-\rho)$$  
$$E[N] = \frac{\rho}{1-\rho}$$  

Page Rank Formulas
- **Last Recently Used (LRU)**: Put the last recently used on top of the priority list
- **Move-Ahead**: Move the last recently used up one (1) ranking in priority
- Full example in Lecture 8 Notes

Operational Analysis
===

OA Basics
- A queueing system has a buffer/queue where arriving jobs wait to be served by a server - after being completed, they depat
- A queueing system must describe:
    1. Arrivals - time between arrivals given by a probability distribution
    2. Queue - size (finite or infinite)
    3. How server operates - # of servers, order of service (FCFS, LCFS, etc), processing times in a probability distribution
- Performance indicators include:
    1. Response time - time from arrival to departure
    2. Throughput - # of jobs served per time unit
- Also two possible pieces of analysis directions
    1. Exact analysis - Try to write down equations that yield the desired performance metric, then solve
    2. Simulation - By generating realizations/samples from the underlying distributions, we can follow the logic of the system to estimate the performance measure(s) of interest
- First cut at analytic models, suppose we have the following data:
    - $A_i(t)$ - # of arrivals to device *i* at time *t*
    - $C_i(t)$ - # of completions (departures) from device *i* at time *t*
    - $B_i(t)$ - Busy/processing time of device *i* at time *t*
- From this data, we can quickly get the following values:
    - $\lambda_i(t)$ - Arrival rate at device *i*  
    $$\lambda_i(t) = A_i(t)/t$$
    - $X_i(t)$ - Throughput at device *i*  
    $$X_i(t) = C_i(t) / t$$
    - $\rho_i(t)$ - Utilization of device *i*  
    $$\rho_i(t) = B_i(t)/t$$
    - $S_i(t)$ - Average processing time at device *i*  
    $$S_i(t) = B_i(t)/C_i(t)$$
- NOTE: We will also assume that the system is *ergodic*, meaning the time averages lead to the underlying means. Only thing to note is:  
$$S_i(t) \rightarrow E[S_i] = 1/\mu_i$$

OA Laws
- **Utilization Law**: Given the throughput and average processing time, the utilization of the system can be calculated by:  
$$\rho_i = X_iE[S_i]$$
- **Forced Flow Law**: Suppose $A_i(t) = C_i(t)$ (jobs in = jobs out). Let $E[V_i]$ be the expected number of visits to the device *i* per job. This requires a reference device, which we will call device 0. By definition, $E[V_0] = 1$, so we have:  
$$E[V_i] = \lim_{t \rightarrow \inf} \frac{C_i(t)}{C_0(t)}$$
- Furthermore, if the system throughput *X* is measured through node 0, the throughput of node *i* is then:  
$$X_i = E[V_i]X$$
- Device Demands
    - **Utilization Law**  
    $$\rho_i = X_i E[S_i]$$
    - **Forced Flow Law**  
    $$X_i = E[V_i]X$$
    - Comining the above...  
    $$\rho_i = E[S_i]E[V_i]X$$
    - Average demand at device *i*  
    $$E[D_i] = E[S_i]E[V_i]$$
    - Therefore  
    $$\rho_i = E[D_i]X$$
    - $E[D_i]$ is the expected processing time on device *i* totalled over all visits of a job. The **bottleneck** of a system would be the device with the **highest E[D_i]**
- **Little's Law**: Relates the number of jobs in a queueing system, $E[N_i]$, the arrival rate of the queueing system, $\lambda_i$, and the mean response time, $E[T_i]$  
$$E[N_i] = \lambda_i E[T_i]$$

Users/Clients
- **Users/Clients**: Consider a model where there are *M* users (clients) who operate as follows:
    1. Each user thinks for a period of time thas has mean $E[Z]$ time units (think time)
    2. At the end of a think time, the user submits the job/request to a subsystem
    3. Once procesing is complete at the subsystem (and returned to the user), the user begins another think time
- **General Response Time**: Consider a system with *M* users connected to a subsystem with *K* nodes. We are interested in the mean response time for the subsystem, $E[T]$. Inside the system, the mean number of jobs $E[N]$ satisfies:  
$$E[N] = XE[T]$$  
$$= E[N_1] + E[N_2] + ... + E[N_K]$$  
$$XE[T] = X_1E[T_1] + X_2E[T_2] + ... + X_KE[T_K]$$
$$E[T] = E[V_1]E[T_1] + E[T_2]E[V_2] + .. + E[V_K]E[T_K]$$  
- This gives the final result:  
$$E[T] = \sum_{i=1}^K E[V_i] E[T_i]$$
- **Interactive Response Time Law**: Given the same system, the total mean cycle time of a client's job is $E[Z] + E[T]$. So, in a given time period of length *t*, each client generates on average  
$$\frac{t}{E[Z] + E[T]}$$  
requests
- The throughput is then given by  
$$X = \frac{M}{E[Z] + E[T]}$$  
- The end result gets us  
$$E[T] = \frac{M}{X} - E[Z]$$

Bottlenecking
- **Bottleneck Analysis**: Let $D=E[D_1] + E[D_2] + ... + E[D_K]$ be the average total demand, $D_{\max} = \max_i E[D_i]$ is the maximum demand in the subsystem. We then have  
$$X \leq \min(\frac{1}{D_{\max}}, \frac{M}{D + E[Z]})$$  
$$E[T] \geq \max(D, MD_{\max} - E[Z])$$
- $D_{\max}$ is the "bottleneck demand" and the device which achieves $D_{\max}$ is the "bottleneck"
- The *M* value that matches the left side of the equations for *X* and $E[T]$ is known as the number of clients that the system can support
    - Below this, performance scales well. Above this, performance degrades considerably

OA Equations (letting $t \rightarrow \inf$)  
$X_i$: Throughput of device *i* (jobs/t)   
$X$: Throughput of the system (jobs/t)  
$\lambda_i$: Arrival rate at device *i* (jobs/t)   
$\rho_i$: Utilization of device *i* (%)   
$\mu_i$: Processing rate at device *i* (jobs/t)  
$M$: Number of clients in the system (#)  
$D$: Average total demand (t/jobs)  
$D_{\max}$: Bottleneck demand (t/jobs)  
$E[S_i]$: Average processing time at device *i* (t/request)   
$E[V_i]$: Average expected number of visits to device *i* (request/job)  
$E[D_i]$: Average demand at node *i* (t/jobs)  
$E[N_i]$: Average number of jobs at node *i* (jobs)  
$E[T_i]$: Average response time at node *i* (t)  
$E[Z]$: Average user think time (t)  
//////  
$$E[S_i] = \frac{1}{\mu_i}$$  
$$X_i = E[V_i] X$$  
$$E[D_i] = E[S_i] E[V_i]$$  
$$\rho_i = X_i E[S_i] = E[S_i] E[V_i] X = E[D_i] X$$  
$$E[N_i] = \lambda_i E[T_i]$$  
**Assuming** no wait time, $\lambda_i = X_i$  
$$\text{# of Requests per Client} = \frac{t}{E[Z] + E[T]}$$  
$$E[T] = \sum_{i=1}^K E[V_i]$$  
$$E[T_i] = \frac{M}{X} - E[Z]$$  
$$D = E[D_1] + E[D_2] + ... + E[D_K]$$  
$$D_{\max} = \max_i E[D_i]$$  
$$X \leq \min (\frac{1}{D_{\max}}, {\frac{M}{D + E[Z]}})$$  
$$E[T] \geq \max (D, MD_{\max} - E[Z])$$  
At the bottleneck, $\rho_{\max} = XD_{\max} \leq 1$  
With one client, $E[T] = E[D_1] + ... + E[D_K] = D \rightarrow E[T] \geq D$  
$$E[T] = \frac{M}{X} - E[Z] \geq MD_{\max} - E[Z]$$  
$$X = \frac{M}{E[Z] + E[T]} \leq \frac{M}{E[Z] + D}$$ 


Exponential Distribution and Poisson Process
===

Exponential Distribution
- REMEMBER: Exponential distirbution follows the memoryless property, meaning that any amount of time that has passed does not change the possible outcome based on the current state:  
$$P(X \gt s + t | X \gt s) = P(X \gt t)$$
- **Property 1**: Given $X_1 ~ Exp(\lambda_1)$, $X_2 ~ Exp(\lambda_2)$, and $X_1, X_2$ are independent, then:  
$$P(X_1 \lt X_2) = \frac{\lambda_1}{\lambda_1 + \lambda_2}$$
- **Property 2**: Given $X_1 ~ Exp(\lambda_1)$, $X_2 ~ Exp(\lambda_2)$, and $X_1, X_2$ are independent, then:  
$$X = min(X_1, X_2) ~ Exp(\lambda_1 + \lambda_2)$$
- Counting Process: Let $N(t)$ be a counting process:
    1. $N(t)$ is nondecreasing
    2. $N(t) = 0,1,2,...$
    - $N(t)$ counts *events* - ie. arrivals
- **Independent Increments**: A process has independent increments if for non-overlapping time intervals $(t_0, t_1), (t_2, t_3), (t_4, t_5), ..., (t_{2n}, t_{2n+1})$, we have:  
$$P(N(t_1) - N(t_0) = k_0, N(t_3) - N(t_2) = k_1, ..., N(t_{2n+1}) - N(t_0{2n} = k_n)$$  
$$=P(N(t_1) - N(t_0) = k_0) * P(N(t_3) - N(t_2) = k_1) * ...$$
- **Stationary Increments**: A process has stationary increments if $\forall s \geq 0$:  
$$P(N(t+s) - N(s) = k) = P(N(t) = k)$$

Exponential Distribution Equations  
$$P(X = a) = \lambda e^{-\lambda a}$$  
$$P(X \leq a) = 1 - e^{-\lambda a}$$  
$$P(a \leq X \leq b) = \int_a^b \lambda e^{-\lambda x} dx$$  
$$P(a \lt b, c) = \frac{\lambda_a}{\lambda_a + \lambda_b + \lambda_c}$$  
$$E[X] = \frac{1}{\lambda_a + \lambda_b + \lambda_c}$$  
$$V(X) = \frac{1}{(\lambda_a + \lambda_b + \lambda_c)^2}$$   

Poisson Process
- **Definition 1**: A poisson process with rate $\lambda$ is a counting process such that:
    1. $N(0) = 0$
    2. The process has independent increments
    3. The number of events in any interval of length *t* is Poisson distributed with mean $\lambda t$. That is, $\forall s, t \geq 0$:  
    $$P(N(t+s) - N(s) = k) = \frac{(e^{-\lambda t})(\lambda t)^k}{k!}, k = 0, 1, ...$$
- **Definition 2**: A Poisson process with rate $\lambda$ is a counting process such that the interarrival times are independent and identially distributed (i.i.d.) exponential random variables with rate $\lambda$ and $N(0) = 0$
- Note, these two definitions are equivalent
- **Merging Poisson Processes**: Given two independent Poisson processes, where process 1 has rate $\lambda_1$ and process 2 has rate $\lambda_2$, the merge of process 1 and process 2 is a single Poisson process with rate $\lambda_1 + \lambda_2$
- **Splitting a Poisson Process**: Given a Poisson process with rate $\lambda$, suppose that each event is classified as "type A" with probability *p* and "type B" with probability $1-p$. Then type A events form a poisson process with rate $p \lambda$, type B events form a Poisson process with rate $(1-p)\lambda$, and these two processes are **independent**. Specifically, if $N_A(t)$ denotes the number of type A events by time t, and $N_B(t)$ denotes the number of type B events by time t, then:  
$$P(N_A(t) = n, N_B(t) = m) = P(N_A(t) = n) * P(N_B(t) = m)$$  
$$= e^{-\lambda t p} \frac{(\lambda t p)^n}{n!} e^{-\lambda t (1-p)} \frac{(\lambda t (1-p))^m}{m!}$$
- **Event Theorem**: Given that one event of a Poisson process has occurred by time *t*, the event is equally likely to have occurred anywhere in $[0, t)$

Poisson Process Equations  
$$P(N_x(t_2) - N_x(t_1) = k) = \frac{(e^{-\lambda t})(\lambda t)^k}{k!}, k = 0, 1, ...$$  
$$P(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}, k = 0, 1, 2, ...$$  
$$E[X] = V(X) = \lambda$$  
- Note that arrivals **always** come in an exponential distribution with the same rate of the Poisson process

Continuous-Time Markov Chains
===

- DTMCs have transitions made only at discrete time steps. This generalizes to transitions that can happen at *any time*, but keep the state space countable (discrete)
- **CTMC Definition**: A CTMC is a continuous-time stochastic process $(X(t), t \geq 0)$, such that $\forall s, t \geq 0$ and $\forall i, j, x(u)$  
$$P(X(t+s) = j | X(s) = i, X(u) = x(u), 0 \leq u \leq s)$$  
$$= P(X(t+s) = k | X(s) = i)$$  
(^ by Markov property)  
$$= P(X(t) = j | X(0) = i) = P_{ji}(t)$$  
(^ by stationary)
- **Residence Times**: Define $\tau_i$ to be the time until the CTMC leaves state *i*, given that the CTMC is currently in state *i*. Must have:  
$$P(\tau_i \gt t + s | \tau_i \gt s) = P(\tau_i \gt t)$$  
But this means that $\tau_i$ is exponentially distributed
- **Limiting Probabilities**: Would like to solve for  
$$\pi_j = \lim_{t \rightarrow \inf} P_{ij}(t)$$  
the limiting probability of being in state *j*
- We calculate this by the rate of transitions into a state equal to the rate of transitions out of a state, ex:  
$$\pi_i(0.3 + 0.5) = (0.25)\pi_0 + (0.4)\pi_2$$
    - We also get the usual sum to 1 equation
    - There equations are known as the **global balance equations**

M/M/1 Queue
- Has the following properties:
    - Single server
    - Arrivals follow a Poisson process with rate $\lambda$
    - Processing/service times follow $Exp(\mu)$ distribution (hence, mean is $1/\mu$)
    - Infinite waiting room
- Let $X(t)$ be the number of jobs in the system at time *t*. The global balance equations are given as:  
$$\lambda \pi_0 = \mu \pi_1$$  
$$(\lambda + \mu) \pi_n = \lambda \pi_{n-1} + \mu \pi_{n+1}, n \geq 1$$
- This solves to the following:  
$$\pi_n = (\frac{\lambda}{\mu})^n \pi_0$$
- Also, given the **utilization/load** of the system as $\rho = \lambda / \mu \lt 1$, and the probability that a server is busy is $1-\pi_0 = \rho$, we get the following:  
$$\pi_0 = 1-\rho$$  
$$\pi_n = (1-\rho) \rho^n$$
- We can also get the following values:  
$$E[N] = \frac{\rho}{1 - \rho}$$  
$$E[T] = \frac{1}{\mu - \lambda}$$
- **Birth-Death Process**: Suppose that $\lambda_n$ is the rate out of state $n$ to $n+1$, and $\mu_n$ is the rate out of $n$ to state $n-1$. This is known as the "Birth-Death Process", the $\lambda$ values are the birth rates and the $\mu$ values are the death rates
- General solution to a birth-death process:  
$$\pi_n = \frac{\lambda_0\lambda_1 ... \lambda_{n-1}}{\mu_1\mu_2 ... \mu_n} \pi_0$$  
$$\pi_0 = \frac{1}{1 + \sum_{n=1}^{\inf} \Pi_{i=1}^n \frac{\lambda_{i-1}}{\mu_i}}$$
- **Little's Law** applies here too, relating the number of jobs in a queueing system, $E[N]$, the arrival rate of the queueing system, $\lambda$, and the mean response time, $E[T]$  
$$E[N] = \lambda E[T]$$

M/M/1/*N* Finite Buffer System
- Same as M/M/1, but arriving jobs (beyond *N* in system) are "lost" or "blocked", not returning at a later time
- Gives us the equations:  
$$\pi_n = (\frac{\lambda}{\mu})^n \pi_0, n=0, 1, ..., N$$  
$$\pi_0 = 1/\sum_{n=0}^N (\lambda/\mu)^n$$  
$$E[N] = \sum_{n=0}^{N} n\pi_n$$
- **Blocking probability** is the probability that the system is full calculated by the steady state of $\pi_N$  
    - Mean number of jobs lost per unit time is then $$\lambda \pi_N$$
    - The actual arrival rate of a system with a blocking probability $\pi_N$ (which can also be seen as throughput) can be calculated as well as $\lambda' = \lambda (1 - \pi_N)$

M/M/Inf Queue
- Each job is now immediately assigned its own processor (or each job its own server)
- Gives us the equations:  
$$\pi_n = \frac{1}{n!} (\frac{\lambda}{\mu})^n \pi_0$$  
$$\pi_0 = e^{-\lambda / \mu}$$
- Final limiting distribution is:  
$$\pi_n = \frac{1}{n!} (\frac{\lambda}{\mu})^n e^{-\lambda / \mu}$$
    - $E[N] = \lambda / \mu$
    - $E[T] = 1/\mu$

M/M/*c* Queue
- *c* processors in parallel and a queue for waiting jobs  
$$\pi_n = \frac{1}{n!} (\frac{\lambda}{\mu})^n \pi_0, n = 0, ..., c-1$$  
$$\pi_0 = [1 + \sum_{n=1}^{c-1} \frac{1}{n!} (\frac{\lambda}{\mu})^n + \frac{1}{c!} (\frac{\lambda}{\mu})^c (\frac{1}{1-\rho})]^{-1}$$
- Where $\rho = \frac{\lambda}{c \mu}$
- Further equations:  
$$E[N_Q] = [\frac{(\lambda/\mu)^c \lambda \mu}{(c-1)!(c\mu - \lambda)^2}] \pi_0$$  
$$E[T_Q] = [\frac{(\lambda/\mu)^c \mu}{(c-1)!(c\mu - \lambda)^2}] \pi_0$$  
$$E[N_Q] = \frac{1}{\mu} + [\frac{(\lambda/\mu)^c \mu}{(c-1)!(c\mu - \lambda)^2}] \pi_0$$  
$$E[N] = \lambda E[T]$$
- **Erlang-C Formula**  
$$P(queueing) = \sum_{n=c}^{\inf} \pi_n$$  
This sum evaluates to:  
$$\frac{1}{c!} (\lambda / \mu)^c(1/(1-\rho)) \pi_0$$
