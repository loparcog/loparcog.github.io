---
layout: post
title:  "4HC3 - Lecture 17"
date:   2020-10-22 11:30:00 -0400
categories: 4HC3
---

Usability Evaluation
===

Usability Evaluation
- Usability testing is one common way of evaluating a UI
    - There are others though, like usability inspections
- Potential problems with usability testing
    - What if we don't have access to users?
    - What if we don't have time/resources?
    - Does a short test capture how users will experience the UI over long periods of time?
        - Good for learnability, but not sure for later use

Usability Inspections
- Evaluations of user interfaces through inspection, generally performed by non-users such as usability experts
- Usability inspection techniques include the following:
- **Heuristic evaluation**: Evaluator (ideally a usability expert) evaluates an interface with respect to a set of guidelines, possibly principles/theories as well
    - Primary goal to identify usability issues and problems with the design of the interface
    - Can be done per-task or interface-wide
    - One or multiple sets of guidelines may be used for different niche types of interfaces (ie. online video games, document creation tool, etc.)
        - Watch out for overlapping guidelines/principles, not worth going over twice
    - Can commonly use a heuristic evaluation sheet, organizing a status report on what was tested and any issues/recommendations
        - Customized based on tasks to test
    - Note that feedback could be objective or subjective
    - **Advantages:**
        - Fast/inexpensive
        - Can be done early in development process w/o users
        - Can be done with internal resources
    - **Disadvantages:**
        - Results influenced by knowledge/bias of reviewer
        - Only one reviewer means they'll miss things
- **Cognitive walkthrough**: Usability inspection method where evaluator(s) step through tasks the users will perform
    - At each step in the task, the evaluator(s) simulate a user's thought process
        - Typically done by answering questions related to user cognition
        - Variations exist depending on the set of questions, ie. Using Norman's 7 stages of actions would be known as a "Norman walkthrough"
        - Four common questions also given in lecture (will the user notice the correct action is available, does the user get appropriate feedback, etc.)
    - Goal is to uncover usability issues, particularly w.r.t learnability
    - Tasks performed according to optimal action sequence
        - Avoid fumbling around, big assumption but want to make sure that optimal path is not confusing
    - Done per-task, rather than for the full UI
    - **Advantages**
        - Similar to heuristic (cost/time, don't need users, can be done internally)
    - **Disadvantages:**
        - Evaluators *do* fumble around, confused with the interface in practice
        - Evaluation is then influenced by this confusion, rather than judging the optimal path
        - Can be **very** time consuming in practice
- **Pluralistic walkthrough**: Group stepping through tasks and interface supports and discussing usability issues at each step
    - Group is made of developers, usability experts, and representative users
    - Done with hardcopy panels, either prototypes or screen displays
    - Facilitator leads the group through the walkthrough, step-by-step through a task
        - Each task is a user action
        - Participants play the role of the user individually in each step
    - At each step, until the task is complete, the facilitator has the participants share their thoughts and notes
    - **Advantages**:
        - Developers gain appreciation for user frustration
        - Re-design ideas incorporate thoughts of all stakeholders present
        - Can produce good usability data early in development 
    - **Disadvantages**:
        - Very time consuming in practice, even more than cognitive (as fast as the slowest member of group)
        - Difficult to schedule everyone at once
        - Nature of walkthrough (optimal path) does not support browsing/navigating behaviours
- Usability Inspections
    - Like usability tests, results can be reported in different formats
        - Formal reports, presentations, or reports/summaries
    - Heuristic evals results might get reported as a per-heuristic 'checklist' with associated result
    - Walkthrough results might get reported as a per-task 'checklist' with associated result

Evaluation during Active Use
- Usability testing and inspection methods are both still very important and relevant, but they come from an era where you couldn't easily fix software after release
    - Most modern software is now delivered as a service over the web
    - Only "shrinkwrapped software" still prominent are console video games, but even those are patched
- Patches and updates help to solve issues post-release
- How to get data on what needs to be fixed/updated?
- Continuous user data logging
    - Log and analyze user data: login frequency, feature usage rates, time on page, etc.
        - Can look for patterns to improve the UI
    - User privacy should be disclosed, if discovered after then trustability is going to sink
        - Telling them will make *some* distrust, but not as much as not telling them
- Forms/Wikis/Social Media
    - Users share opinions, look for them and try to build off of them
- Beta testing
    - Software released to a limited number of users
        - Form of acceptance testing, typically used to identify bugs in software
        - Typically one of the last types of testing conducted
    - Modern SaaS software can have a very long beta test, as new features added and tested
    - Idea of "perpetual beta" also a thing