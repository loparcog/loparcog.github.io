---
layout: post
title:  "4E03 - Lecture 20"
date:   2020-11-02 16:30:00 -0400
categories: 4E03
---

Performance Evaluation
===

Simulation
- Typically used when exact analysis is not possible/difficult
    - Not possible in a lot of cases, making a lot of assumptions for some systems
- This is an **approximate/estimate** approach
- Going to essentially "run" the system for generated values, see what we get
- Three pieces to this problem:
    1. How to "generate" the values?
    2. How to construct the simulation?
        - No "one size fits all", will learn a general approach
    3. How can we make sense of the output to get some sort of system approximation/estimate?
- Random number generation
    - Two issues to discuss:
    1. How do computers generate random numbers?
    2. How does one generate a sample from a given distribution?
    - Pseudo random number generation
        - Computers not capable of generating "truly" random numbers (like rolling a die)
        - There are techniques that sample the physical world: For example, cloudfare's wall of lava lamps
        - Best that can be done is a sequence of *pseudo random numbers* - appears to be random, but is not
            - In other words, passes statistical tests of randomness
    - Many approaches RNG
    - Goal here is to give one (primitive) approach, won't need to actually code this
    - Multiplicative Congruential Method
        - Choose $x_0$ (the seed) and recursively compute the values $x_n, n \geq 1$ via:  
        $$x_n = ax_{n-1} mod m$$  
        where $a, m$ are given positive integers
            - Starting with the same number gives the same sequence of values, which is *bad*, but can also be useful!
            - Matlab always starts with the same seed
            - Main takeaway is psudo random number generators always based on a seed
        - $x_n$ is an integer between 0 and $m-1$
        - Take $x_n / m$ as a sample from $U[0,1]$
        - After a finite amount of time, sequence will repeat
        - *m* should be a large prime number that can fit in the word size
        - For a 32-bit word, where the first bit is the sign, $m=2^{31} - 1$ and $a=2^7$ work well
    - Desirable properties of a PRNG
        1. For any seed, the resultant sequence has the "appearance" of being a sequence of independent random variables, from $U[0,1]$
        2. For any seed, the number of samples that can be generated before repetition begins is large
        3. The values can be efficiently computed (fast time to get a random number)
    - PRNG: Assumptions
        - There is lots of information out there about PRNG
        - For our purposes, assume we have a built in PRNG that follow the properties described above
- Generating Samples from a Given Distribution
    - Discrete case
        - Generate a sample, x, from a discrete random variable having given pmf $P(X = x_j) = p_j$
        - Suppose that $(x_j)$ is a finite set
        - There is then a simple algorithm: first generate a sample *u* from $U[0,1]$. If $u \lt p_1$, set $x = x_1$, else if $u \lt p_1 + p_2$, set $x = x_2$, continue for all values of *p*
        - If the set of possible values is infinite, need to truncate at some point
        - The time required to generate a sample is proportional to the number of possible values
    - Continuous case
        - Want a mapping from a $U[0,1]$ random variable to $F(x)$:  
        $$u = P(0 \lt U \leq u) = P(0 \lt X \leq x) = F(x)$$  
        So, $x = F^{-1}(u)$
            - NOTE: $F^{-1}(u)$ is NOT $1/F(u)$, it's the *functional inverse*
        - Ex: $F(x)$ is an exponential distribution with rate $\lambda$; $F(x) = 1 - e^{-\lambda x}, x \geq 0$  
        $$F^{-1}(u) = -ln(1-u)/\lambda$$  
        If *u* is a sample from $U[0,1]$, then $1-u$ is also a sample from $U[0,1]$, so we can replace $1-u$ by *u*
            - To inverse the function, we would do the following:  
            $$1-e^{-\lambda x} = u$$  
            $$e^{-\lambda x} = 1-u$$
            $$ -\lambda x = ln(1-u)$$
            $$x = \frac{-1}{\lambda} ln(1-u)$$
- Constructing a Simulation
    - A *discrete event simulation* has the following general structure. There are sets of *variables* and *events*. Generally, we have the following variables:
        1. Time variable (*t*) - The elapsed (simulated) time
        2. Counter variables - Track the number of times that certain events have occurred (by time *t*)
        3. State variables - "State" of the system at time *t*, the state should be chosen such that the next state can be uniquely determined given any event occurrence
        4. Output variables
    - Whenever an event occurs, value of variables updated
    - Must determine when next event occurs - keep an event list (may not be explicit) that lists the nearest future events and when they are scheduled to occur
    - Ex: Simulate two single-server queues in series (output of the first feeds the second)
        1. Time between arrivals: $Exp(\lambda)$
        2. Processing times of first server: $Exp(\mu_1)$
        3. Processing times of second server: $Exp(\mu_2)$
        4. FCFS processing at both servers
        - Will go through next lecture