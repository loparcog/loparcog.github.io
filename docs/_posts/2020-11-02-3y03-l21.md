---
layout: post
title:  "3Y03 - Lecture 21"
date:   2020-11-02 10:30:00 -0400
categories: 3Y03
---

Chapter 7: Point Estimation
===

Recall...
- Population vs Sample
    - Random variable (X, Y, Z) vs data observations (x, y, z)
    - Distribution parameters
    - AAA (finish)

Statistical Inference
- Two groups, parameter estimation and hypothesis testing
    - Param estimation is also divided into two groups, point estimation and confidence interval
    - Hypothesis testing will be gone through later in the course

Point Estimator
- A **point estimate** of some population parameter $\theta$ is a single numerical value $\hat{\theta}$ of a statistic $\hat{\Theta}$. The statistic $\hat{\Theta}$ is called the **point estimator**
- Examples of use:
    1. Use a sample mean $\bar{x}$ to estimate the population mean, $\mu$:  
    $$\hat{\mu} = \bar{x}$$
    2. Use sample median *m* to estimate the population mean, $\mu$:  
    $$\hat{\mu} = m$$  
    3. Use sample median *m* without outliers to estimate mean, $\mu$:  
    $$\hat{\mu} = m_{\text{without outliers}}$$
    4. Population variance $\sigma^2$, sample variance $s^2$:  
    $$\hat{\sigma}^2 = s^2$$  
    5. Population standard deviation, sample standard deviation:  
    $$\hat{\sigma} = s$$  
    6. Proportion *p* of population:  
    $$\hat{p} = \text{the number of items in sample}$$
- What about when there are several estimators for the same value? Which should we use? What should we do with the difference between their values?
    - Dealt with for point estimation

Bias of an Estimator
- The point estimator $\hat{\Theta}$ is an **unbiased estimator** for the parameter $\theta$ if the mean of the point estimator is equal to the population parameter:  
$$E(\hat{\Theta}) = \theta$$
- If the estimator is **not unbiased**, then the difference is:  
$$E(\hat{\Theta}) - \theta$$  
this is called the **bias** of the estimator $\hat{\Theta}$
- Examples of use:
    1. The unbiased estimator of population mean $\mu$ is sample mean $\bar{x}$
    2. The unbiased estimator of population variance $\sigma^2$ is sample variance $s^2$
    3. Sample standard deviation $s$ is **NOT** an unbiased estimator of population standard deviation $\sigma$

Ex: Let *X* be a binomial random variable with parameter *p*. Assume we have *n* observations. The point estimator of $p^2$ is:  
$$\hat{p^2} = \frac{x^2}{n^2}$$  
Find if this is an unbiased estimator, and if not, what is its bias?
- SOLN:  
Check if $E(\hat{p^2}) = p^2$:  
$$E(\hat(p^2)) = E[\frac{x^2}{n^2}]$$  
$$= \frac{1}{n^2} E[x^2]$$  
Recall that $V(x) = E[x^2] - (E[x])^2$, we can then get:  
$$E[x^2] = V(x) + (E[x])^2$$  
Subbing this in, we get:  
$$= \frac{1}{n^2} (V(X) + [E(X)]^2)$$  
$$= \frac{V(X)}{n^2} + \frac{(E[X])^2}{n^2}$$  
We can also use the equations of a binomial random variable, since $X ~ bin(n,p)$, which gives us $E[X] = np$, $V(X) = np(1-p)$:  
$$= \frac{np(1-p)}{n^2} + \frac{n^2p^2}{n^2}$$  
$$= \frac{p(1-p)}{n} + p^2$$  
This value is not equal to $p^2$, therefore:  
$\hat{p^2} = \frac{x^2}{n^2}$ is NOT an unbiased estimator  
The bias is then:  
$$E[\hat{p^2}] - p^2 = (\frac{p(1-p)}{n} + p^2) - p^2 = \frac{p(1-p)}{n}

Minimum Variance Unbiased Estimator
- If we consider all unbiased estimators $\theta$, the one with the smallest variance is called the **minimum variance unbiased estimator (MVUE)**
    - Examples:  
    Population mean $\mu$, MVUE is sample mean $\bar{X}$  
    Population variance $\sigma^2$, $V(\bar{X}) = \sigma^2/n$
- If $X_1, X_2, ..., X_n$ is a random sample of size *n* from a normal distributions with mean $mu$ and variance $\sigma^2$, the sample mean $\bar{X}$ is the MVUE for $\mu$

Standard Error of an Estimator
- The **standard error** of an estimator $\hat{\Theta} is its standard deviation given by:  
$$\sigma_{\hat{\Theta}} = \sqrt{V(\hat{\Theta})}$$  
If the standard error involves unknown parameters that can be estimated, substitution of those values into $\sigma_{\hat{\Theta}}$ produces an **estimated standard error**, denoted by $\hat{\sigma_{\hat{\Theta}}}$
    - Can also denote as:  
    $$SE(\hat{\Theta}) = \sqrt{V(\hat{\Theta})}$$  
    $$V(\bar{X}) = \frac{\sigma^2}{n}$$  
    $$\sigma_{\bar{X}} = SE(\bar{X}) = \sqrt{V(\bar{X})} = \sqrt{\frac{\sigma^2}{n}} = \frac{\sigma}{\sqrt{n}}$$  
    Note: $\sigma$ is the population standard deviation
    - Substituting the population standard deviation with the sample standard deviation $s$, we can also get:  
    $$\hat{\sigma_{\bar{X}}} = \frac{s}{\sqrt{n}}$$

Mean Squared Error of an Estimator
- The **mean squared error of an estimator** $\hat{\Theta}$ of the parameter $\Theta$ is defined as:  
$$MSE(\hat{\Theta}) = E(\hat{\Theta} - \theta)^2
