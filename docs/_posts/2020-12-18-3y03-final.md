Final Exam Review
===

Exam Coverage
- Note: All textbook sections are based on V7 of the textbook
- **Probability (Ch.2 - Ch.5)**
- Ch.2: 2.1-.7, .9
- Ch.3: 3.1-.4, .6-.8
- Ch.4: 4.1-.2, .5,  
.6 (**omit** $N(\mu, \sigma^2) \approx Poisson$),   
.7
- Ch.5: 5.1 (**omit** discrete random variables, $\mu, \sigma^2$),  
5.2 (**omit** conditional probability distribution),  
5.4, 5.6
- **Statistics (Ch.6 - CH.?)**
- Ch.6: 6.1-.4, .7
- Ch.7: 7.1-.2,  
.3 (**omit** bootstrap)
- Ch.8: 8.1-.2, .4
- Ch.9: 9.1-.2,  
.3 (**omit** 9.3.2)
- Ch.10: 10.2 (**omit** 10.2.2)
- Ch.11: 11.1-.5,  
.6 (**omit** CI of population proportion)

Review
- Ch.2: Definition and Terminology of Probability
    - Meaning for sample space, event, outcomes, axiom of probability
    - Sets (computation, $\cup, \cap$, c, distributive law, DeMorgan's law)
        - Venn diagrams will be included in this section
    - Probability of events ($\cap, \cup$, c)
        - Conditional probability, independence
        - $P(A \cap B) = P(A) P(B)$
        - $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
    - Random Variables, $X, Y, Z$
- Ch.3: Discrete Random Variables
    - Probability Mass Function (pmf):  
    $$f(x) = P(X = x)$$  
    where $X$ is the random variable and $x$ is the number/value
    - Cumulative Distribution Function (cdf):  
    $$F(x) = \sum_{X \leq x} f(x)$$
    - Mean, variance, standard deviation
    - Binomial, Geometric, Negative Binomial, Hypergeometric, and Poisson Distribution
        - Know pdf, cdf, mean, variance equations
- Ch.4: Continuous Random Variables
    - Probabilty Density Function (pdf):  
    $$f(x)$$  
    - Cumulative Density Function (cdf):  
    $$F(x) = \int_{-\infty}^x f(u) du$$
    - Mean, variance, standard deviation
    - Normal Distribution $N(\mu, \sigma^2)$
        - Know standard normal distribution and how to use the table to approximate binomial distribution
    - Exponential Distribution
- Ch.5: Joint Probability
    - Joint pdf:  
    $$f_{XY}(x,y), F_{XY}(x,y)$$  
    - Independence:  
    $$f_{XY} = f_X f_Y$$  
        - Marginal pdf
    - Covariance:  
    $$cov(x,y)$$  
    - Correlation:  
    $$P_{XY}: corr(x,y)$$
    - Linear function of random variables ($X_1, ..., X_n$):  
    $$Y = c_0 + c_1 x_1 + c_2 x_2 + . .. + c_n x_n$$
        - $E(Y) = c_0 + c_1 E(X_1) + ... + c_n E(X_n)$
        - $V(Y) = c_1^2 V(X_1) + ... + c_n^2 V(X_n) + \text{covariance term}$
- Ch.6: Basics of Statistics
    - Sample, Random sample
        - Sample: observations, $x_1, ..., x_n$ (numbers)
        - Random Sample: $X_1, X_2, ..., X_n$ (random variables)
    - Sample mean $\bar{x}$, sample variance $s^2$, sample standard deviation $s$, median $m$, quartiles $Q_1, Q_3$, range, mode
    - Graphical visualization
        - Stem and Leaf (deep, leaf)
        - Histogram (frequency, relative frequency, cumulative frequency)
        - Box Plot (vertical/horizontal, outliers)
        - Probability Plot (Q-Q plot)
        - Scatter Plot (Dashed line)
- NOTE: Statistical inference (3 groups)
    1. Point estimation (estimation, Ch. 7)
    2. Confidence interval (estimation, Ch. 8)
    3. Hypothesis testing (Ch. 9)
    - All covered with two populations in Ch. 11
- Ch.7: Point Estimation
    - $\mu$: $\bar{x}, $m$, $\bar{x}$ without outliers, etc...
    - $\sigma^2$L: $s^2$, $s^2$ without outliers, etc...
    - $\hat{\Theta}$ as point estimator
    1. $E(\hat{\Theta})$: Unbiased estimator
    2. $V(\hat{\Theta}), E(\hat{\Theta})$ MVUE (minimum variance unbiased estimator)
    3. Estimated standard error of $\hat{\Theta}$, $SE(\hat{\Theta})$
    4. Mean squared error $E[(\hat{\Theta} - \theta)^2] = V(\hat{\Theta}) + (bias)^2$
    - Efficiency of two estimator $\hat{\Theta}_1, \hat{\Theta}_2$ (optimal):  
    $$\frac{MSE(\hat{\Theta}_1)}{MSE(\hat{\Theta}_2)}$$
    - Central Limit Theory: N (large enough) ~ $N(\mu, \sigma^2) \to ...$
- Ch.8: Confidence Interval
    1. Population Mean
    - Population variance $\sigma^2$ known:  
    $$z = \frac{\bar{x} - \mu}{\sigma/\sqrt{n}}$$
        - Two-sides interval:  
        $$LR = \bar{x} \pm Z_{\alpha/2} (\sigma/\sqrt{n})$$  
        - One-side interval:  
        $$L = \bar{x} - Z_{\alpha} (\sigma/\sqrt{n}), R = \bar{x} + Z_{\alpha} (\sigma/\sqrt{n})$$  
    - Population variance $\sigma^2$ unknown
        - Sample size *n* large enough ($n \geq 30$):  
        $$z = \frac{\bar{x} - \mu}{\sigma / \sqrt{n}}$$
            - Uses standard normal (z) distribution
        - Sample size $n \lt 30$:  
        $$T = \frac{\bar{x} - \mu}{\sigma / \sqrt{n}}$$
            - Uses t-distribution (fat-tailed)
            - Two-sides interval:  
            $$LR = \bar{x} \pm t_{\alpha/2, n-1} (s/\sqrt{n})$$  
            - One-side interval:  
            $$L = \bar{x} - t_{\alpha, n-1} (s/\sqrt{n}), R = \bar{x} + t_{\alpha, n-1} (s/\sqrt{n})$$  
    2. Population Proportion *p*
    - Binomial(n,p): $\mu = np, \sigma^2 = np(1-p)$
        - z-score, two-sides interval:  
        $$\hat{p} \pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$  
        one-side interval:  
        $$\hat{p} +/- z_{\alpha}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$
- Ch.9: Hypothesis Testing
    1. Population Mean
    - Population variance $\sigma^2$ known: **z-test**
        - Two-sides test: $H_1: \mu \neq \mu_0$
        - One-side test: $H_1: \mu \gt \mu_0, \mu \lt \mu_0$
    - Population variance $\sigma^2$ unknown
        - Sample size $n \geq 30$: z-test
        - Sample size $n \lt 30$: t-test
    2. Population Proportion
    - Value given in table
- Ch.10: Multiple populations
    - $\mu_1, \sigma_1^2, p_1$ vs $\mu_2, \sigma_2^2, p_2$
    1. Population Mean $H_0: \mu_1 - \mu_2 = \mu_0 \text{ or } \mu_1 = \mu_2$
        - Population variance $\sigma_1^2, \sigma_2^2$ known:  
        $$\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}$$
        - Population variance $\sigma_1^2, \sigma_2^2$ unknown:  
        $$\frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2}$$

- Ch.11: Linear Regression
    - $Y = \beta_0 + \beta_1 x + \epsilon$
        - $\beta_0$: intercept  
        $\beta_1$: slope  
        $\epsilon$: error term
    - $H_0: \beta_1 = 0, H_1: \beta_1 \neq 0$
    - Check $\epsilon$ with residual, follows $N(0, \sigma^2)$

Midterm 1 Notes
===

Probability Theory
===

Experiments & Spaces
- Anything that produces data is an **experiment**
- A *random* experiment can produce different outcomes even when repeated in the same conditions
    - A **sample space**, *S*, is the set of all outcomes of a random experiment
    - A sample space is continuous if it contains real numbers in its range, otherwise it is discrete
- An **event** is a subset of the sample space (like for flipping 3 coins, the outcomes that have two or more heads is an event)
- Given three events $E, E_1, E_2$ from a sample space *S*, then:
    - The **union**,  
    *$E_1 \cup E_2$ := {x $\in$ $S$ : x $\in E_1$ or x $\in E_2$}*  
    the **intersection**  
    *$E_1 \cap E_2$ := {x $\in$ $S$ : x $\in E_1$ and x $\in E_2$}*  
    and the **complement**  
    *$E'$ = {x $\in$ $S$ : x $\notin$ $E$}*  
    are all events as well
- Also some interesting things to note:
    - If $E$ $\subseteq$ $S$ is any event, then $E$ $\cup$ $E'$ = $S$ and $E$ $\cap$ $E'$ = $\emptyset$
    - Both $S$ and $\emptyset$ are also events, and $S'$ = $\emptyset$ and vice versa
    - (A')' = A
    - Distributivity:
        - (A $\cup$ B) $\cap$ C = (A $\cap$ C) $\cup$ (B $\cap$ C) 
        - (A $\cap$ B) $\cup$ C = (A $\cup$ C) $\cap$ (B $\cup$ C)
    - DeMorgan's Laws:
        - (A $\cup$ B)' = A' $\cap$ B'
        - (A $\cap$ B)' = A' $\cup$ B'
- Two events are **mutually exclusive** if they cannot happen simultaneously, or in mathematical terms, $E_1 \cap E_2 = \emptyset$

Permutations & Combinations
- Suppose we have *r* experiments, and the *i*th experiment has $n_i$-many possible outcomes. Then, the total number of outcomes for running all experiments consecutively is:  

$$\prod_{i=1}^{r} n_i = n_1 n_2 ... n_{r-1} n_r$$

- A **permutation** calculates the number of ways we can arrange a given set of data w.r.t order
- Given n distinct objects, the number of ways to **permutate** them is:

$$n! = n \cdot (n-1)\cdot(n-2)\cdot...\cdot3\cdot2\cdot1$$

- By similar reasoning, we can make a more general counting technique for permutations. Given a set of n distinct objects, the number of ways to permutate r $\leq$ n of them is:

$$P_{r}^{n} = nPr = n \cdot (n-1) \cdot ... \cdot (n - r + 1) = \frac{n!}{(n-r)!}$$

- An example for this would be all three letter words with no repeated letters, permutating 3 choices from a choice of 26, which would be $P_3^{26} = 26 \cdot 25 \cdot 24$
- For permutating a set of data with $n = n_1 + ... + n_r$ many objects and $n_i$ identical many objects of type *i*, the number of unique permutations of the object is:  

$$\frac{n!}{n_1!n_2!...n_r!}$$

- A **combination** calculates the number of ways we can get a subset of a set of data without any regard to order
- Given a group of *n* distinct objects, the number of ways to choose $r \leq n$ of them is:

$$C_r^n = nCr = {n \choose x} = \frac{n(n-1)...(n-r+1)}{(n-r)!}=\frac{n!}{(n-r)!r!}$$

- The numbers ${n \choose x}$ are called **binomial coefficients**

Axioms of Probability
- Probability is used to quantify likelihood/chance that an outcome of a random experiment will occur
- Whenever a sample space consists of *N* possible outcomes that are all equally likely, the probability of each outcome is $1/N$
- In a discrete space, the probability of event *E*, denoted as $P(E)$, is the sum of the probabilities of the outcomes in *E*
- A probability must satisfy the following properties:
    - $P(S) = 1$, if S is the sample space
    - $0 \le P(E) \le 1$ for any event *E*
    - For two events, if $E_1 \cap E_2 = \emptyset$, then $P(E_1 \cup E_2) = P(E_1) + P(E_2)$
        - Vice versa is true for this
- Also note the following axioms:
    - $P(\emptyset) = 0$
    - $P(E') = 1 - P(E)$
- The probability of a union is denoted as:  

$$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$

- If they are mutually exclusive, the intersection would be 0, so you could just add their separate probabilities
- For three or more events, the following equations can be used:  

$$P(A \cup B \cup C) = P[(A \cup B) \cup C] = P(A \cup B) + P(C) - P[(A \cup B) \cap C]$$
  
$$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)$$
- The conditional probability of event B given event A is denoted as:  

$$P(B \| A) = \frac{P(A \cap B)}{P(A)}$$, for P(A) \> 0

- Conditional probabilities can also be turned into an intersection given the multiplication rule:  
$P(A \cap B) = P(B \| A)P(A) = P(A \| B)P(B)$
- For any events *A* and *B*, **totality** can be shown given:  

$$P(B) = P(B \cap A) + P (B \cap A') = P(B \| A)P(A) + P(B \| A')P(A')$$

- Two statements are also independent if any of the following is true:  
$P(A \| B) = P(A)$  
$P(B \| A) = P(B)$  
$P(A \cap B) = P(A) P(B)$
    - Furthermore any number of events are independent if:  
    $P(E_1 \cap E_2 \cap ... \cap E_n) = P(E_1) * P(E_2) * ... * P(E_n)$

Random Variables & Distributions
===

Random Variables and Associated Functions
- A **random variable** is a function that assigns a real number to each outcome in a sample space of a random experiment
    - Denoted by an uppercase letter, such as *X*. After an experiment is conducted, the measured value of the random variable is denoted by a lowercase letter, such as *x* = 70
    - A discrete random variable is a random variable with a finite (or countably infinite) range
        - Ex. number of scratches on a surface, proportion of defective parts among 1000 tested
    - A continuous random variable is a random variable with an interval (finite or infinite) of real numbers for its range
        - Ex. Electrical current, length, pressure, temp, time
- The **probability distribution** of *X* is a description of the probabilities associated w/ the possible values of *X*. For a discrete random var, the distribution is often specified by just a list of the possible values along with their probabilities
- **Probability Mass Function**
    - For a discrete random variable *X* with possible values $x_1, x_2, ..., x_n$, a *probability mass function* (PMF) is a function such that:
        1. $f(x_i) \geq 0$
        2. $\sum^n_{i=1} f(x_i) = 1$
        3. $f(x_i) = P(X = x_i)$
- **Cumulative Distribution Function**
    - The cumulative distribution function of X is a function $F: \mathbb{R} \rightarrow [0,1]$ such that, for all $x \in \mathbb{R}$:  
    $F(x) = P(X \leq x)$
    - The cumulative distribution function (cdf) of a DRV *X* is another way to specify the distribution of *X*
- Suppose *X* is a DRV with range {$x_1, x_2, x_3, ...$}, pmf $f(x)$, and cdf $F(x)$. Then $F(x)$ satisfies the following properties:
    1. For all $x \in \mathbb{R}, F(x) = P(X \leq x) = \sum_{x_i \leq x} f(x_i)$
    2. For all $x \in \mathbb{R}, 0 \leq F(x) \leq 1$
    3. For all $x, y \in \mathbb{R}, \text{ if } x \leq y, \text{ then } F(x) \leq F(y)$
- Note, if $f(x)$ and $F(X)$ are the pmf and cdf of a DRV *X* with range {$x_1, x_2, x_3, ...$}, then they are "inter-definabile", in the sense that:  

$$F(x_n) = \sum_{i \leq n} f(x_i)$$

and  

$$f(x_n) = F(x_n) - F(x_{n-1})$$

- Also note, $\lim_{n \rightarrow \inf} F(n) = 1$
- The **mean/expected value** is the average outcome, or the value of the random variable we expect to see most often:  

$$\mu = E(X) := \sum_{i=1} x_i f(x_i)$$

- The **variance** is a measure of how spread out the distribution is, and the square root of the variance is normalized to be the **standard deviation**. The variance is given as follows:

$$\sigma^2 = V(X) := E[(X - \mu)^2] = \sum_{i-1} (x_i - \mu)^2 f(x_i)$$

- Note, the variance can also be given as:  

$$V(X) = \sum_{i=1} x_i^2 f(x_i) - \mu^2 = E(X^2) - E(X)^2$$

- If *X* is a DRV with range {$x_1, x_2, ...$} and pmf $f(x)$, and $h: \mathbb{R} \rightarrow \mathbb{R}$ is any function, then the composition $h(X)$ is also a DRV with range {$h(x_1), h(x_2), ...$} (note h(x_i) does not need to be distinct). Furthermore, the mean and variance can be computed as follows:  
$E(h(X)) = \sum_{i=1} h(x_i) f(x_i)$  
$V(h(X)) = \sum_{i=1} [h(x_i) -  E(h(x_i))]^2 f(x)$
    - A notable case of this is when $h(x) = ax+b$ is linear. Then:  
    $E(h(X)) = aE(X) + b$  
    $V(h(X)) = a^2 V(X)$
    - In general though, $E(h(X)) \neq h(E(X))$

Distributions
- **Binomial Distribution**
    - An experiment with two possible outcomes (success and failure) is called a "Bernoulli Trial"
    - If a Bernoulli trial is successful with probability *p*, then it fails with probability 1-*p*
    - Let *X* be be the number of successful outcomes in *n*-many independent Bernoulli trials
        - We say *X* is a **binomial random variable** with parameters *p* and *n*, sometimes writing as $X ~ Bin(n,p)$
    - If $X ~ Bin(n,p)$ is a binomial random variable, then the functions are given as follows
        - pmf:  
        $f(x) = \binom{n}{x} p^x (1-p)^{n-x}$  
        (Where range of X is x=1, 2, ..., n-1, n)
        - avg:  
        $E(X) = np$
        - var:  
        $Var(X) = np(1-p)$
- **Geometric Distribution**
    - Related to the binomial distribution
    - Running a Bernoulli trial, with success probability of *p*. Let *X* be the number of trials we need to run until a successful trial occurs
        - Then *X* is a **geometric random variable** with parameter *p*
        - The interpretation of pmf $f(n)$ for a geometric random variable is the probability that there are *n*-1 many failures (probability = 1-*p*), followed by a success (probability = *p*)
    - If *X* is a geometric random variable, then the functions are given as follows
        - pmf:  
        $f(x) = (1-p)^{x-1} p$  
        (Where x = 0, 1, 2, 3, ...)
        - avg:  
        $E(X) = \frac{1}{p}$
        - var:  
        $V(X) = \frac{1-p}{p^2}$
- **Inverse Binomial Distribution**
    - Generalization of the geometric distribution
    - Suppose we have a Bernoulli trial with probability *p* of success, and let $r \geq 1$ be an integer
        - Let *X* be the number of trials we need to run until we reach *r*-many successful trials
        - Given this, *X* is an **inverse binomial random variable** with parameters *p* and *r*
            - A geometric random variable is an inverse binomial random variable with r=1
    - Suppose *X* is an inverse binomial random variable, then the functions are given as follows
        - pmf:  
        $f(x) = \binom{x-1}{r-1}(1-p)^{x-r} p^r$  
        (Where $x=r, r+1, r+2, ...$)
            - Also, if $X_i$ is the number of trials required to get the *i*-th success, then $X_i$ is geometric, and $X = X_1 + X_2 + ... + X_r$
        - avg:
        $E(X) = \frac{r}{p}$
        - var:
        $V(X) = \frac{r(1-p)}{p^2}$

Midterm 2 Notes
===

Notes from Poisson Distribution to Point Estimators
===

Poisson Distribution
---

- Used to model number of events occurring within a given time interval
    - Can also be used for number of events in a distance, area, volume, any sort of **continuous** domain
- If *X* is a **poisson random variable**, where *x* is the discrete number of occurrences and $\lambda$ is the average number of events per time interval, with *T* as the total time, then the functions are given as follows
    - pmf:  
    $f(x) = \frac{e^{-\lambda}(\lambda)^x}{x!}$
    - avg:  
    $E(X) = \lambda T$
    - var:  
    $V(X) = \lambda T$

CRV
---

- Probability Density Functions
    - **Continuous Random Variable**: A random variable with an interval (finite or infinite) with real numbers in its range
    - For a continuous random variable *X*, a **probability density function** is a function such that:
        1. $f(x) \geq 0$
        2. $\int_{-\infty}^{\infty} f(x) dx = 1$
        3. $P(a \leq X \leq b) = \int_a^b f(x) dx =$ area under f(x) fro *a* to *b* for any *a* and *b*
    - **Histogram**: An approximation to a probability density function
        - An example would be for *X* as a continuous random variable, and any *a* and *b*:  
        $P(a \leq X \leq b) = P(a \lt X \leq b) = P(a \leq X \lt b) = P(a \lt X \lt b)$
- Cumulative Distribution Function
    - For a continuous random variable *X*, the **cumulative distribution function** is:  
    $F(x) = P(X \leq x) = \int_{-\infty}^x f(u) du$  
    (For $-\infty \lt x \lt \infty$)
        - The probability density function can be determined from the cumulative distribution function by differentiating:  
        Given F(x), $f(x) = \frac{dF(x)}{dx}$, as long as the derivative exists
        - We can also get full ranges from this:  
        $$P(a \leq X \leq b) = \int_a^b f(u) du$$
- Mean/Variance of a Continuous Random Variable (CRV)
    - Suppose that *X* is a continuous random variable, with probability density function $f(x)$
        - The mean/expected value of *X* is:  
        $\mu = E(X) = \int_{-\infty}^{\infty} x f(x) dx$
        - The variance of *X* is:  
        $$\sigma^2 = V(X) = \int_{-\infty}^{\infty} (x-\mu)^2 f(x) dx = \int_{-\infty}^{\infty} x^2 f(x) dx - \mu^2$$
    - Furthermore, we can compute the expected value with a random variable function as follows:  
    $E[h(X)] = \int_{-\infty}^{\infty} h(x) f(x) dx$
        - In the special case that $h(X) = aX + b$, for any constants *a* and *b*, then:  
        $E[h(X)] = aE(X) + b$

CRV Distributions
---

- **Continuous Uniform Distribution**
    - A CRV with pdf:  
    $$f(x) = \frac{1}{b-a}, a \leq x \leq b$$  
    is a continuous uniform random variable
    - This also gives us the functions:  
    $$F(x) = P(x \leq X) = \frac{x-a}{b-a}$$
    $$E(X) = \frac{a+b}{2}$$  
    $$V(X) = \frac{(b-a)^2}{12}$$
- **Normal Distribution**
    - A CRV with pdf:  
    $$f(x) = \frac{1}{\sqrt{2 \pi \sigma}} e^{\frac{-(x-\mu)^2}{2 \sigma^2}}, -\infty \lt x \lt \infty$$  
    is a normal random variable, with distribution $N(\mu, \sigma^2)$
    - If the distribution is $N(0,1)$, then it is a **standard normal random variable**, denoted as $Z$, and gives us:  
    $$\Phi(z) = P(Z \leq z)$$
    - We can standardize any normal random variable with $E(X) = \mu, V(X) = \sigma^2$:  
    $$Z = \frac{X - \mu}{\sigma}$$  
    We can also do the same for any values:  
    $$z = \frac{x - \mu}{\sigma}$$  
    and then plug the $z$ value into the table to get an associated probability, noted as $\Phi z$
    $$P(X \lt x) = P(Z \lt z) = \Phi z$$
- **Normal Approximation to the Binomial and Poisson Distributions**
    - If $X$ is a **binomial random variable** with parameters *n* and *p*:  
    $$Z = \frac{X - np}{\sqrt{np(1-p)}}$$  
    is approximately a standard normal random variable
    - To approximate with a binomial random variable with a normal distribution, a **continuity correction** is applied as follows:  
    $$P(X \leq x) = P(X \leq x + 0.5)$$  
    $$\approx P(Z \leq \frac{x + 0.5 - np}{\sqrt{np(1-p)}})$$  
    $$P(x \leq X) = P(x - 0.5 \leq X)$$  
    $$\approx P(Z \leq \frac{x - 0.5 - np}{\sqrt{np(1-p)}})$$  
    **NOTE:** This approximation is **ONLY** good for $np \gt 5, n(1-p) \gt 5$
    - If $X$ is a **Poisson random variable** with $E(X) = V(X) = \lambda$:  
    $$Z = \frac{X - \lambda}{\sqrt{\lambda}}$$  
    Is approximately a standard normal random variable
    - The same **continuity correction** applies, and this is **ONLY** good for $\lambda \gt 5$
- **Exponential Distribution**
    - The random variable $X$ that equals the distance between successive events from a Poisson process, with mean number of events $\lambda \gt 0$ per unit interval, is an **exponential random variable** with parameter $\lambda$. The pdf of $X$ is then:  
    $$f(x) = \lambda e^{- \lambda x}, 0 \leq x \lt \infty$$
    - We also get the following values:  
    $$F(X) = 1 - e^{-\lambda x}$$  
    $$E(X) = \frac{1}{\lambda}$$  
    $$V(X) = \frac{1}{\lambda^2}$$
    - This distribution also supports the **memoryless property**, stating that the probability of an event does not depend on the time that has already passed or time since the last event

Joint Probability Distributions
---

- **ONLY** for CRV's
- Let $X,Y$ be two CRV's, which may or may not be related to one another. The **joint probability density function** of $X,Y$ is a function $f_{X,Y}(x,y)$ satisfying the following properties:
    1. $$f_{X,Y} \gt 0, \forall x,y \in \mathbb{R}$$
    2. $$\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X,Y}(x,y) dx dy = 1$$
    3. For any region in $A \subseteq \mathbb{R}^2$:  
    $$P((X,Y) \in A) = \int \int_A f_{X,Y}(x,y) dx dy$$
- Note the mean of the joint probability distribution can be found with:  
$$E(XY) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} xy f_{X,Y}(x,y) dx dy$$  
- We can also divide this function in two, getting the **marginal probability densities** as follows:  
$$f_X(x) = \int_{R_Y(y)} f_{X,Y}(x,y) dy$$  
$$f_Y(y) = \int_{R_X(x)} f_{X,Y}(x,y) dx$$  
where $R_X(x)$ is the range of all values $X$ is defined on, and same with $Y$
- We can then compute the expected value and variance of each as follows:  
$$E(X) = \int_{-\infty}^{\infty} x f_X(x) dx = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x f_{X,Y}(x,y) dx dy$$  
$$V(X) = E((x - \mu_X)^2) E(X^2) - E(X)^2$$  
This can be some similarly for $Y$
- We can say $X,Y$ are **independent** iff:  
$$f_{X,Y}(x,y) = f_X(x) f_Y(y)$$
    - If $X,Y$ are independent and jointly distributed on region $R$, then $R$ must be rectangular
    - $R = I_1 * I_2$ for intervals $I_1, I_2$, giving us:  
    $$1 = \int_{I_2} \int_{I_1} f_{X,Y} (x,y) dx dy$$  
    $$= (\int_{I_1} f_X(x) dx)(\int_{I_2} f_Y(y) dy)$$
- We can get the expected value of a function with two random variables $h(X,Y)$ as follows:  
$$E(h(X,Y)) = \int \int h(x,y) f_{X,Y}(x,y) dx dy$$
- We can also measure the linear relationship, or **covariance** of $X$ and $Y$, given as:  
$$cov(X,Y) = \sigma_{XY} = E(XY) - E(X)E(Y)$$
    - If $X,Y$ are independent, then $\sigma_{XY} = 0$, but the reverse is **not true**
- The **correlation** between two random variables $X,Y$, denoted as $\rho_{XY}$ is:  
$$\rho_{XY} = \frac{cov(X,Y)}{\sqrt{V(X)V(Y)}} = \frac{\sigma_{XY}}{\sigma_X\sigma_Y}$$
    - If the covariance is positive/negative/zero, then the correlation is also positive/negative/zero, but the values can range to:  
    $$-1 \leq \rho_{XY} \leq 1$$  
    so independent variables would also have $\rho_{XY} = 0$

Linear Functions of Random Variables
---

- Given random variables $X_1, X_2, ..., X_p$ and constants $c_0, c_1, c_2, ..., c_p$:  
$$Y = c_0 + c_1 X_1 c_2 X_2 ... c_p X_p$$  
is a **linear function** of $X_1, X_2, ..., X_p$
- The **mean of a linear function** can be calculated as:  
$$E(Y) = c_0 + c_1 E(X_1) + c_2 E(X_2) + ... + c_p E(X_p)$$
- Similarly, the **variance of a linear function** can be calculated as:  
$$V(Y) = c_1^2 V(X_1) + c_2^2 V(X_2) + ... + c_p^2 V(X_p) + 2 \sum \sum_{i \lt j} c_i c_j cov(X_i, X_j)$$
    - However, if $X_1, X_2, ..., X_p$ are *independent*, then:  
    $$V(Y) = c_1^2 V(X_1) + c_2^2 V(X_2) + ... + c_p^2 V(X_p)$$
- **Mean of an Average**: If $\bar{X} = (X_1 + X_2 + ... X_p)/p$, with $E(X_i) = \mu$ for $i = 1, 2, ..., p$:  
$$E(\bar{X}) = \mu$$
- **Variance of an Average**: If $X_1, X_2, ..., X_p$ are also independent, with $V(X_i) = \sigma^2$ for $i = 1, 2, ..., p$:  
$$V(\bar{X}) = \frac{\sigma^2}{p}$$
- NOTE: You can also use this for equations like the following:  
$$P(\bar{X} \leq x) = P(\frac{\bar{X} - \mu}{\sqrt{\sigma^2/p}} \leq \frac{x - \mu}{\sqrt{\sigma^2/p}})$$  
$$P(\bar{X}_1 - \bar{X}_2 \geq x) = P(\frac{(\bar{X}_1-\bar{X}_2) - (\mu_1 - \mu_2)}{\sqrt{\sigma^2_1/p + \sigma_2^2/p}} \geq \frac{(x) - (\mu_1 - \mu_2)}{\sqrt{\sigma^2_1/p + \sigma_2^2/p}})$$
- **Reproductive Property of the Normal Distribution**: If $X_1, X_2, ..., X_p$ are independent normal random variables with $E(X_i) = \mu_i$ and $V(X_i) = \sigma_i^2$ for $i = 1, 2, ..., p$, then:  
$$Y = c_0 + c_1X_1 + c_2 X_2 + ... + c_p X_p$$  
is a **normal random variable**, with:  
$$E(Y) = c_0 + c_1 \mu_1 + c_2 \mu_2 + ... + c_p \mu_p$$  
$$V(Y) = c_1^2 \sigma_1^2 + c_2^2 \sigma_2^2 + ... + c_p^2 \sigma_p^2$$

Numerical Summaries of Data
---

- **Sample Mean**: If a sample of *n* values are taken from a population, with each sample denoted as $x_1, x_2, ..., x_n$, then the sample mean is:  
$$\bar{x} = \frac{x_1 + x_2 + ... + x_n}{n}$$
- **Sample Variance**: If $x_1, x_2, ..., x_n$ is a sample of *n* observations, the sample variance is:  
$$s^2 = \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n-1}$$
    - Similarly, you can get the **sample standard deviation** using the positive root
- **Sample Range**: The sample range of *n* observations is given as:  
$$r = max(x_i) - min(x_i)$$

Descriptive Statistics (Graphing)
---

- **Stem-and-Leaf Diagrams**
    - Steps to construct a stem-and-leaf diagram:  
        1. Divide each number $x_i$ into two parts: a stem, consisting of one or more leading digits, and a leaf
        2. List the stem values in a vertical column, and record all the leafs beside it
        4. Write the units for stems and leaves on the display
    - We can use this to divide data into quartiles, with $q_1$ having approx 25% below it, $q_2$ having 50%, and $q_3$ having 75%
        - We can find these values using the following:  
        $q_1 = \text{median between start value and median}$  
        $q_2 = \text{median value}$  
        $q_3 = \text{median between median and end value}$  
        - An outlier is an observation that passes $q_1 - 1.5(IQR)$ or $q_3 + 1.5(IQR)$
    - In general, the $n$th percentile is a data value such that $n$% of observations are below it, and $1-n$% are above
    - We can use the **interquartile range (IQR)** as a measure of variability:  
    $$IQR = q_3 - q_1$$

- **Frequency Distributions and Histograms**
    - More compact summary of data than a stem-and-lead diagram. To construct a frequency distribution, we must divide the range of data into intervals, usually called class intervals/cells/bins. Choosing the number of bins approx equal to the square root of the number of observations works well in practice
        - Relative frequencies found by dividing the observed frequency in each bin by the total number of observations
    - The histogram is a visual display of the frequency distribution. To construct:
        1. Label the bin boundaries on a horizontal scale
        2. Mark and label the vertical, scale with the frequencies or the relative frequencies
        3. Above each bin, draw a rectangle where height is equal to the frequency (or relative frequency) corresponding to that bin
        - Sometimes unequal bin widths will be used in a histogram. When this is the case, the rectangle's area should be proportional to the bin frequency. This implies the rectangle height should be:  
        $$\text{Rectangle Height} = \frac{\text{Bin Frequency}}{\text{Bin Width}}$$
- **Box Plots**
    - The following image helps to explain the plot:  
    ![img]({{ site.url }}/assets/3y03/boxplot.PNG)

- **Probability Plots**
    - Let $x_1, x_2, ..., x_n$ be a given data set, and $x_{(1)}, x_{(2)}, ..., x_{(n)}$ be the same data set, ordered from smallest to largest
    - Let $z_1, z_2, ..., z_n$ be the value of $z$ with the property that:  
    $$\Phi(z_i) = \frac{i-0.5}{n}$$
        - We can use that fraction calculation to match with the closest value from the normal distribution table, getting a $z$ value, which we will use as the y values of the graph
    - Plot the $(x_i, z_i)$ pairs onto a graph and check for correlation
        - We can then do an **Anderson-Darling Normality Test** to see if the population is normally distributed
        - If the p-value is **less than 0.05**, then we can conclude it **does not** follow a normal distribution
        - If the p-value is **greater than 0.10**, we can conclude that it **does** follow a normal distribution
        - If the p-value is **between 0.05 and 0.10**, then the results are inconclusive
    - By eye, we're just looking that all the points are on the line or somewhere close

Point Estimators
---

- A major component of statistical inference is called **parameter estimation**
    - A **parameter**, $\theta$, is any numerical feature of a population/dataset (mean, variance, etc.)
- A **point estimate** of some population parameter $\theta$ is a single numerical value $\hat{\theta}$ of a statistic $\hat{\Theta}$. The statistic $\hat{\Theta}$ is called the **point estimator**
    - An example of this could be how a sample mean $\bar{x}$ is a point estimator of the population mean $\mu$, that is:  
    $$\hat{\mu} = \bar{X}$$
- The random variables $X_1, X_2, ..., X_n$ are a **random sample** of size *n* if:
    1. The $X_i$'s are independent random variables
    2. Every $X_i$ has the same probability distribution
- A **statistic** is any function of the observation in a random sample
- A few sample statistics can be seen as follows:
    - Sample mean:  
    $$\bar{X} = \frac{X_1+X_2+...+X_n}{n}$$
    - Sample variance: $S^2$
    - Sample standard deviation: $S$
- The probability distribution of a statistic is called a **sampling distribution**
    - Depends on many factors like sample size, sample method, distribution of $X$, but can be helped with the central limit theorem
- **Central Limit Theorem**: If $X_1, X_2, ..., X_n$ is a random sample of size *n* taken from a population (finite/infinite) with mean $\mu$ and finite variance $\sigma^2$, and if $\bar{X}$ is the sample mean, the limiting form of the distribution is:  
$$Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}}, n \to \infty$$
    - This means that for any *z*:  
    $$P(\frac{\bar{X} - \mu}{\sigma/\sqrt{n}}) = \phi(z)$$
    - **NOTE**: To use this, you will need $n \geq 30$, unless the distribution is ""nice enough"" (eg. symmetric, unimodal), in which you can use $n \geq 5$
- **Unbiased Estimators**
    - The point estimator $\hat{\Theta}$ is an **unbiased estimator** for the parameter $\theta$ if  
    $$E(\hat{\Theta}) = \theta$$  
    otherwise, the estimator is biased, and the **bias** of the estimator is given by:  
    $$E(\hat{\Theta}) - \theta$$
    - Note that the sample variance:  
    $$S^2 = \frac{\sum_{i=1}^n (X_i - \bar{X})^2}{n-1}$$ 
    is an unbiased estimator of variance
        - $S = \sqrt{S^2}$ however, is **NOT** an unbiased estimator of standard deviation, but is still pretty good
- **Variance of a Point Estimator**
    - If we consider all unbiased estimators of $\theta$, the one with the smallest variance is called the **minimum variance unbiased estimator (MVUE)**
        - This should always be chosen as the point estimator
        - Also, note that if $X_1, X_2, ..., X_n$ is a random sample of size *n* from a normal $\bar{X}$ is **always** the MVUE of $E(X)$
- **Standard Error of an Estimator**
    - The **standard error** of an estimator $\hat{\Theta}$ is its standard deviation, given by:  
    $$\sigma_{\hat{\Theta}} = \sqrt{V(\hat{\Theta})}$$
    - If the standard error involves unknown parameters that can be estimated, substitution of those values into $\sigma_{\hat{\Theta}}$ produces an **estimated standard error**, denoted by $\hat{\sigma_{\hat{\Theta}}}$
    - The standard error of the distribution of $\bar{X}$ is given by:  
    $$\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}$$
    - If we didn't know $\sigma$, but we knew the sample standard deviation *S*, we can get the estimated standard error by:  
    $$\hat{\sigma}_{\bar{X}} = \frac{S}{\sqrt{n}}$$
- **Mean Square Error of an Estimator**
    - The **mean squared error (MSE)** of an estimator $\hat{\Theta}$ of the parameter $\theta$ is defined as:  
    $$MSE(\hat{\Theta}) = E(\hat{\Theta} - \theta)^2$$
    - This can also be generalized to:  
    $$MSE(\hat{\Theta}) = V(\hat{\Theta}) + (\text{bias})^2$$
    - The **relative efficiency** of $\hat{\Theta}_2$ to $\hat{\Theta}_1$ is given as:  
    $$\frac{MSE(\hat{\Theta}_1)}{MSE(\hat{\Theta}_2)}$$
    
Final Notes
===

Confidence Interval on the Mean of a Normal Distribution, **Variance Known**
- An interval estimate for a population parameter is called a **confidence interval**
- Suppose $X_1, X_2, ..., X_n$ is a random sample from the normal distribution with unknown mean $\mu$ and known variance $\sigma^2$, then the sample mean $\bar{X}$ is normally distributed with mean $\mu$ and variance $\sigma^2$, we may standardize $\bar{X}$ by:  
$$Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}}$$
- A confidence interval estimate for $\mu$ is an interval of the form $l \leq \mu \leq u$, where the endpoints *l* and *u* are computed from the sample data
    - Because difference samples produce different values of *l* and *u*, these end-points are values of random variables *L* and *U* respectively. Suppose we can determine values of *L* and *U* such that the following probability statement is true:  
    $$P(L \leq \mu \leq U) = 1 - \alpha$$  
    where $0 \leq \alpha \leq 1$. There is a probability of $1 - \alpha$ of selecting a sample for which the CI will contain the true value of $\mu$
    - The end points are called the lower and upper confidence limits (bounds), and $1 - \alpha$ is called the **confidence coefficient**
- If $\bar{x}$ is the sample mean of a random sample of size *n* from a normal population with known variance $\sigma^2$, a $100(1-\alpha)\%$ confidence interval on $\mu$ is given by:  
$$\bar{X} - z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X} + z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}$$  
where $z_{\alpha / 2}$ is the value such that $\phi(z_{\alpha / 2}) = \alpha / 2$
- If $\bar{x}$ is used as an estimate of $\mu$, we can be $100(1-\alpha)\%$ confident that the error $|\bar{x} - \mu|$ will not exceed a specified amount *E* when the sample size is:  
$$n = \left(\frac{z_{\alpha / 2} \sigma}{E}\right)^2$$

Confidence Interval on the Mean of a Normal Distribution, **Variance Unknown**
- Let $X_1, X_2, ..., X_n$ be a random sample from a normal distribution with unknown mean $\mu$ and unknown variance $\sigma^2$. The random variable:  
$$T = \frac{\bar{X} - \mu}{S / \sqrt{n}}$$  
has a *t* distribution with $n-1$ degrees of freedom
- A $100(1-\alpha)\%$ confidence interval on $\mu$ is given by:  
$$\bar{x} - t_{\alpha / 2, n-1} s/\sqrt{n} \leq \mu \leq \bar{x} + t_{\alpha / 2, n-1} s/\sqrt{n}$$  
where $t_{\alpha / 2, n-1}$ is the upper $100\alpha/2$ percentage point of the *t* distribution with $n-1$ degrees of freedom

Large-Sample Confidence Interval for a (Binomial) Population Proportion
- If *n* is large, the distribution of:  
$$Z = \frac{X - np}{\sqrt{np(1-p)}} = \frac{\hat{P} - p}{\sqrt{\frac{p(1-p)}{n}}}$$  
is approximately standard normal, where $\hat{P} = X/n$
- A $100(1-\alpha)\%$ confidence interval on the proportion *p* of the population that belongs to this class is:  
$$\hat{p} - z_{\alpha / 2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \leq p \leq \hat{p} + z_{\alpha / 2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$  
where $z_{\alpha / 2}$ is the upper $\alpha / 2$ percentage point of the standard normal distribution
- The sample size for a given error value is:  
$$n - \left( \frac{z_{\alpha/2}}{E} \right)^2 p(1-p)$$

Hypothesis Testing for a Single Variable
- A **statistical hypothesis** is a statement about the parameters of one or more populations
    - General structure consists of a guess, and an alternate guess
- Structure is formally as follows:
    - $H_0$, the **Null Hypothesis**: This is the statement we initially assume to be true
        - Usually in the form $\theta = r$ for some value *r*
        - For example, we may guess $\mu = 50$
    - $H_1$, the **Alternate Hypothesis**: A statement that contradicts the null hypothesis. The alternate hypothesis can take several forms. We can have:
        - $\theta \neq r$ (two-sided alternate hypothesis)
        - $\theta \gneq r$ (upper one-sided alternate hypothesis)
        - $\theta \lneq r$ (lower one-sided alternate hypothesis)
- General strategy is as follows:
    1. Assume $H_0$
    2. Consider the data: Is there something that is very unlikely/implausible given that $H_0$ is true?
    3. If YES, reject $H_0$ in favour of $H_1$
    4.If NO, accept $H_0$
- We use this to test if a parameter has changed, test a theory, conformance testing, etc.
- Method for testing is as follows:
    1. Assume the null hypothesis is true, $H_0 : \theta = r$
    2. Pick an estimator for your parameter, $\hat{\Theta}(X_1, ..., X_n)$
    3. Choose a *critical region* determined by some critical values
        - For example, for a two-sided alternate hypothesis, we could choose a critical region to be the complement of $C = \mathbb{R} (r-l, r+u)$ for critical values $r-l$ and $r+u$, making the critical region $C = (-\infty, r-l] \cup [r+u, \infty))$
    4. Take a sample $x_1, ..., x_n$ and compute a point estimate $\hat{\theta} = \hat{\Theta}(x_1, ..., x_n)$
    5. Is the point estimate in the critical region? In other words, $\hat{\theta} \in C$? If yes, reject $H_0$ and accept $H_1$. If $\hat{\theta} \notin C$, then accept $H_0$
    - The critical region is determined by how likely a sample statistic is to take a value if $H_0$ is true
- There are four possible outcomes to a hypothesis test:
    1. If $H_0$ is true and we accept $H_0$
    2. If $H_1$ is true and we reject $H_0$
    3. If $H_0$ is true and we reject $H_0$ in favour of $H_1$, then we say we made a "Type I Error"
    4. If $H_0$ is false (so $H_1$ is true) and we accept $H_0$ then we say we have made a "Type II Error"
    - We define the *"significance level"* of the test to be the probability of making a Type I Error, which we call $\alpha = P(\text{Type I Error})$
    - The *"power"* of the test is $1 - \beta$, where $\beta = P(\text{Type II Error})$

Fixed Significance Level Testing
- One way to determine a critical region is to require that our test has a fixed significance level $\alpha$
- Suppose $\hat{Theta}$ is an estimator for parameter $\theta$ and we have a null hypothesis $H_0: \theta = r$ and two-sided alternate hypothesis $H_1: \theta \neq r$
- We fix a significance level $\alpha$ and choose critical values based on this value
- In this two sided case, we aim to find a symmetric region defined by critical values $r - a$ and $r + a$ such that:  
$$\alpha = P(\text{Reject } H_0 | H_0 \text{ is True})$$  
$$ = P(\hat{\Theta} \in (-\infty, r-a] \cup [r+a, \infty) | H_0 \text{ is True})$$
- Similar process for one-sided tests

*P*-values
- Gives a more dynamic approach to hypothesis testing than the fixed significance level approach
- Suppose we have a test with a null hypothesis $H_0$, and we have collected a sample of data $(x_1, ..., x_n)$
- The *P*-value of the test is the smallest significance level that would lead to a rejection of $H_0$ with the collected sample
    - Can think of the *P*-value as the probabiliy of being in a sort of variable critical region. The *P*-value is sometimes called the *"observed significance"*
- Let's consider a general two sided test with $H_0: \theta = r$ and $H_1: \theta \neq r$ and estimator $\hat{\Theta}(x_1, ..., x_n)$
- Suppose we take a sample $(x_1, ..., x_n)$ and produce a point estimate $\hat{\theta} = \hat{\Theta}(x_1, ..., x_n)$
- Assuming $H_0$, our "observed" critical values are $r \pm | r - \hat{\theta} | $
- Then the *P*-value of the test is:  
$$P\text{-value} = P(\hat{\Theta} \in (-\infty, r - | r - \hat{\theta} | ] \cup [r + | r - \hat{\theta} |, \infty) | \theta = r)$$
- Given a hypothesis test and observation $\hat{\theta}$, the *P*-value of the observation is the probability of making an observation at least as far from $\theta = r$ as $\hat{\theta}$
- Another way to think of *P*-value is as a measure of the risk that we make an incorrect design if we reject $H_0$ based on the given sample data
    - So for example, if we make an observation/point estimate $\hat{\theta}$ that has a very high *P*-value, then we are at high risk of making a Type I error if we reject $H_0$
- We can use *P*-values to refine the fixed significance level testing procedure:
    - Fix a significance level $\alpha$ and construct a critical region based on it
    - The observed value $\hat{\theta}$ is in the critical region **if and only if** the *P*-value is at most $\alpha$, and so we reject $H_0$ iff $P\text{-value} \leq \alpha$
    - Conversely, we accept $H_0$ iff $P\text{-value} \gt \alpha$

Relationship between Hypothesis Testing and Confidence Intervals
- Let $\theta$ be an unknown parameter. There is a close relationship between a hypothesis test for $\theta$ and confidence intervals for $\theta$
- Suppose $(L,U)$ is a $100(1-\alpha)\%$ confidence interval for $\theta$ constructed around the point estimate $\hat{\theta}$
- Consider a two sided hypothesis test with $H_0: \theta = r$ and $H_1: \theta \neq r$
    - Then the observation $\hat{\theta}$ leads to a rejection of $H_0$ if and only if $r \neq (L,U)$
- This gives us an equivalent way of performing fixed significance level testing
    - Given a test $H_0: \theta = r$ and $H_1: \theta \neq r$, choose test statistic $\hat{\Theta}$ and a significance level $\alpha$
    - For a point estimate $\hat{\theta} = \hat{\Theta}(x_1, ..., x_n)$, construct the $100(1-\alpha)\%$ confidence interval around $\hat{\theta}$
    - If *r* is in the confidence interval, accept $H_0$
    - If *r* is not in the confidence interval, reject $H_0$ in favour of $H_1$

Tests on the Mean of a Normal Distribution, Variance **Known**  
![img]({{ site.url }}/assets/3y03/muvk.PNG)

Type II Error and Choice of Sample Size
- With the following test:  
$$H_0: \mu = \mu_0, H_1: \mu \neq \mu_0$$  
suppose that the null hypothesis is false and that the true value of the mean is $\mu = \mu_0 + \delta$, say, where $\delta \gt 0$. Then when $H_1$ is true, the distribution of the test statistic $Z_0$ is:  
$$Z_0 \approx N \left(\frac{\delta \sqrt{n}}{\sigma}, 1 \right)$$
- The probability of a Type II Error for two-sided test is given as:  
$$\beta = \Phi \left(z_{\alpha/2}-\frac{\delta \sqrt{n}}{\sigma} \right) - \Phi \left(-z_{\alpha/2}-\frac{\delta \sqrt{n}}{\sigma} \right)$$
- The appropriate sample size for a particular value of $\beta$ with a given $\alpha, \delta$ can also be found with (two- sided):  
$$n \approx \frac{(z_{\alpha/2} + z_\beta)^2 \sigma^2}{\delta^2}, \delta = \mu - \mu_0$$
- One-sided:  
$$n \approx \frac{(z_{\alpha} + z_\beta)^2 \sigma^2}{\delta^2}, \delta = \mu - \mu_0$$

Tests on the Mean of a Normal Distribution, Variance **Unknown**
- When *n* is large enough, the sample standard deviation *s* can be substituted for $\sigma$ in the test procedures with little effect. Thus, although we have given a test for the mean of a normal distribution with known $\sigma^2$, it can be easily converted into a large-sample test procedure for unknown $\sigma^2$. The large sample test relies on the **central limit theorem**
- ![img]({{ site.url }}/assets/3y03/muvuk.PNG)

Tests on a Population Proportion
- Modelling the occurrence of defectives with the binomial distribution is usually reasonable when the binomial parameter *p* represetns the proportion of defective idtems produced
    - Consequently, many engineering decision problems involve hypothesis testing about *p*
- An approximate test based on the normal approximation t the binomial is given. As noted earlier, this approximate procedure will be valid as long as *p* is not extremely close to 0 or 1, and if the sample size is relatively large
- Let *X* be the number of observations in a random sample of size *n* that belongs to the class associated with *p*. Then if the null hypothesis $H_0: p = p_0$ is true, we have $X \approx N[np_0, np_0(1-p_0)]$
- ![img]({{ site.url }}/assets/3y03/thbp.PNG)

Type II Error and Choice of Sample Size
- Approximate sample size for a two-sided test on a binomial proportion is given as:  
$$n = \left[ \frac{z_{\alpha/2} \sqrt{p_0(1-p_0) + z_\beta\sqrt{p(1-p)}}}{p-p_0}   \right]^2$$
- For a one-sided test:  
$$n = \left[ \frac{z_{\alpha} \sqrt{p_0(1-p_0) + z_\beta\sqrt{p(1-p)}}}{p-p_0}   \right]^2$$

Hypotheses Tests on the Difference in Means, Variances **Unknown**
- **Case 1:** $\sigma_1^2 = \sigma_2^2 = \sigma^2$  
$$H_0: \mu_1 - \mu_2 = \Delta_0, H_1: \mu_1 - \mu_2 \neq \Delta_0$$
    - Let $X_{11}, ..., X_{1n_1}$ be a random sample of $n_1$ observations from the first population, and $X_{21}, ..., X_{2n_2}$ be a random sample of $n_2$ observations from the second population
    - Let $\bar{X}_1, \bar{X}_2, S_1^2$ be the sample means and variances, respectively. Now the expected value of the difference of sample means $\bar{X}_1 - \bar{X}_2$ is:  
    $$E(\bar{X}_1 - \bar{X}_2) = \mu_1 - \mu_2 $$  
    so $\bar{X}_1 - \bar{X}_2$ is an unbiased estimator of the difference in means
    - The variance of $\bar{X}_1 - \bar{X}_2$ is:  
    $$V(\bar{X}_1 - \bar{X}_2) =\sigma^2(1/n_1 + 1/n_2)$$
    - The pooled estimator of $\sigma^2$, denoted by $S_p^2$ is given as:  
    $$S_p^2 = \frac{(n_1 - 1)S_1^2 + (n_2-1)S_2^2}{n_1 + n_2 - 2}$$  
    - ![img]({{ site.url }}/assets/3y03/twodist.PNG)
- **Case 2:** $\sigma_1^2 \neq \sigma_2^2$
    - If $H_0: \mu_1 - \mu_2 = \Delta_0$ is true, the statistic:  
    $$T_0^* = \frac{\bar{X}_1 - \bar{X}_2 - \Delta_0}{\sqrt{S_1^2/n_1 + S_2^2/n_2}}$$  
    is distributed approximately as *t* with degrees of freedom given by (rounded down to the nearest integer):  
    $$v = \frac{(s_1^2/n_1 + s_2^2/n_2)^2}{\frac{(s_1^2/n_1)^2}{n_1 - 1} + \frac{(s_2^2/n_2)^2}{n_2 - 1}}$$

Empirical Models
- The collection of statistical tools used to model/explore relationships between variables that are related in a nondeterministic manner is called **regression analysis**
- We present the situation in which there is only one independent/predictor variable *x*, and the relationship with the response *y* is assumed to be linear. It is probably reasonable to assume that the mean of the random variable *Y* is related to *x* by the following straight-line relationship:  
$$Y = \beta_0 + \beta_1x + \epsilon$$  
where the slope and intercept of the line are called **regression coefficients** and $\epsilon$ is the random error term
    - We call this model the **simple linear regression model** because it has only one independent variable or regressor
- Suppose that the mean and variance of $\epsilon$ are 0 and $\sigma^2$, respectively. Then:  
$$E(Y | x) = \beta_0 + \beta_1 x, V(Y | x) = \sigma^2$$
- Suppose that the true relationship between *Y* and *x* is a straight line and that the observation *Y* at each level of *x* is a random variable:  
$$Y = \beta_0 + \beta_1 x + \epsilon$$  
where the intercept $\beta_0$ and the slope $\beta_1$ are unknown regression coefficients
- Suppose that we have *n* pairs of observations $(x_1, y_1), ..., (x_n, y_n)$. The estimates of $\beta_0$ and $\beta_1$ should result in a line that is a "best fit" to the data. We can estimate these parameters using the method of **Least Squares**
- We may express the *n* observations in the sample as:  
$$y_i = \beta_0 + \beta_1 x_i + \epsilon_i, i = 1,2,...,n$$  
and the sum of the squares of the deviations of the observations from the true regression line is:  
$$L = \sum_{i=1}^n \epsilon_i^2 = \sum_{i=1}^2 (y_i - \beta_0 + \beta_1 x_i)^2$$
- The **least squares estimates** of the intercept and slope in the simple linear regression model are:  
$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$$  
$$\hat{\beta}_1 = \frac{\sum_{i=1}^n y_i x_i - \frac{(\sum_{i=1}^n y_i)(\sum_{i=1}^n x_i)}{n}}{\sum_{i=1}^n x_i^2 - \frac{(\sum_{i=1}^n x_i)^2}{n}}$$  
where $\bar{x} = \frac{\sum x_i}{n}, \bar{y} = \frac{\sum y_i}{n}$
- The fitted or estimated regression line is therefore:  
$$\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x$$  
    - Note that each pair of observations satisfies the relationship:  
    $$y_i - \hat{\beta}_0 + \hat{\beta}_1 x_i + e_i, i = 1, 2, ..., n$$  
    where $e_i = y_i - \hat{y}_i$ is called the **residual**
    - The residual describes the error in the fit of the model to the *i*th observation $y_i$
- Let  
$$S_{xx} = \sum_{i=1}^n (x_i - \bar{x})^2 = \sum_{i=1}^n x_i^2 - \frac{(\sum x_i)^2}{n}$$  
and  
$$S_{xy} = \sum_{i=1}^n (y_i - \bar{y})(x_i - \bar{x})^2 = \sum_{i=1}^n x_iy_i - \frac{(\sum x_i)(\sum y_i)}{n}$$ 
- The residuals $e_i$ are used to obtain an estimate of $\sigma$. The sum of squares of the residuals, often called the **error sum of squares** is:  
$$SS_E = \sum_{i=1}^n e_i^2 = \sum_{i=1}^n (y-i-\hat{y}_i)^2$$
- Therefore, an unbiased estimator of $\sigma^2$ is:  
$$\hat{\sigma}^2 = \frac{SS_E}{n-2}$$  
- Note that $SS_E$ can also be calculated with:  
$$SS_E = SS_T - \hat{\beta}_1 S_xy$$  
where $SS_T = \sum_{i=1}^n (y_i - \bar{y})^2 = \sum_{i=1}^n y_i^2 - n\bar{y}^2$ is the total sum of squares of the response variable *y*
- $\hat{\beta}_1$ is an unbiased estimator in simple linear regression of the true slope $\beta_1$ and $V(\hat{\beta}_1) = \sigma^2/S_{XX}$
- $\hat{\beta}_0$ is an unbiased estimator of the intercept $\beta_0$ and $V(\hat{\beta}_0) = \sigma^2 \left[ \frac{1}{n} + \frac{\bar{x}^2}{S_{XX}} \right]$
- The **estimated standard error** of the slope and intercept are:  
$$se(\hat{\beta}_1) = \sqrt{\frac{\hat{\sigma}^2}{S_{XX}}}$$  
$$se(\hat{\beta}_0) = \sqrt{\hat{\sigma}^2 \left[ \frac{1}{n} + \frac{\bar{x}^2}{S_{XX}} \right]}$$