---
layout: post
title:  "4E03 - Final Notes"
date:   2020-12-13 11:00:00 -0400
categories: 4E03
---

Probability
===
NOTE: Skipping the basic probability work along with independent events since those were reviewed back for 3Y03, just going over main things I think would be useful

Random Variables
- A random variable *X* (capital letters) is a real-valued function of the outcome of an experiment
- Can be discrete or continuous
- We will use the **cumulative distribution function** (distribution, cdf) to define probabilities of events, defined as $F_X(x)$:  
$$F_X(x) = P(X \leq x)$$
    - We can just use $F(x)$ is the variable is clear
- **Continuous Random Variables**
    - For quantities that take on values on a continuum, involving real numbers, ie. time
    - $F(x)$ is continuous
    - The density function is given as:  
    $$f_X(x) = \frac{dF_X(x)}{dx}$$  
    $$P(a \leq X \leq b) = F_X(b) - F_X(a) = \int_a^b f_X(x) dx$$  
    $$\int_{-\inf}^{\inf} f_X(x) dx = 1$$
- **Discrete Random Variables**
    - For discrete values, a range NOT containing real numbers
    - The **probability mass function** (pmf) gives the probability that a random variable equals a value:  
    $$p_X(i) = P(X = i)$$  
    $$P(j \lt X \leq k) = F_X(k) - F_X(j) = \sum_{j \lt i \leq k} p_X(i)$$  
    $$\sum_i p_X(i) = 1$$
- **Expected Value** (or mean) is given by the following equations for $E[X]$
    - Discrete:  
    $$E[X] = \sum_i ip_X(i)$$
    - Continuous:  
    $$E[X] = \int_{-\inf}^{\inf} xf_X(x) dx$$
- **Higher Moments** can compute the *k*th moment of a probability, given by the following equations for $E[X^k]$
    - Discrete:  
    $$E[X^k] = \sum_i i^kp_X(i)$$
    - Continuous:  
    $$E[X^k] = \int_{-\inf}^{\inf} x^kf_X(x) dx$$
    - Important ones are k=1 (mean) and k=2
- **Variance** measures the expected deviation from the mean (how spread out the distribution is)  
$$Var(X) = \sigma_X^2 = E[X^2] - (E[X])^2$$

Distributions
- **Geometric Distribution**
    - Where $q$ is the probability of success, $1-q$ is the probability of failure, and $p_X(k)$ is the probability that success first happens on the *k*th trial  
    $$p_X(k) = q(1-q)^{k-1}, k = 1, 2, ...$$
    $$E[X] = \frac{1}{q}$$  
    $$Var(X) = \frac{1-q}{q^2}$$
- **Poisson Distribution**
    - Has one parameter of rate, $\lambda$, ang has pmf:  
    $$p_X(k) = \frac{e^{-\lambda}\lambda^k}{k!}, k=0, 1, 2...$$  
    $$E[X] = Var(X) = \lambda$$  
    Also note the following property:  
    $$\sum_{k=0}^{\inf} e^{-\lambda}\frac{\lambda^k}{k!} = e^{-\lambda}e^{\lambda} = 1$$
- **Uniform Distribution**
    - Denoted by $U(a, b)$, random variable is equally likely to take values between a and b  
    $$f(x) = \{^{1/(b-a), a \leq x \leq b}_{0 \text{ otherwise}}$$  
    $$E[X] = \frac{a+b}{2}$$  
    $$Var(X) = \frac{(b-a)^2}{12}$$
- **Exponential Distribution**
    - One parameter, "rate" $\lambda$  
    $$f_X(x) = \{^{\lambda e^{-\lambda x}, x \geq 0}_{0, x \lt 0}$$  
    $$F_X(x) = \{^{1-e^{-\lambda x}, x \geq 0}_{0, x \lt 0}$$  
    $$E[X] = 1/\lambda$$  
    $$Var(X) = 1/\lambda^2$$
    - Also note, the **memoryless property** applies to this distribution. This states that the future is independent of the past, given the present

Performance Introduction
- **Throughput**: How many requests per unit time can the data centre handle?
- **Response Time**: How long is a job in the data centre (frim arrival to departure)?
- **Energy Consumption**: How much energy is the data centre consuming?
- **Reliability**: What is the likelihood of an outage in a given period of time?
- **Workload**: Average number of requests per time unit, likelihood of a "large" number of requests in a given time interval, etc.
- **Response Time**: Average response time, likelihood of a "long" response time, etc.
- Essentially, we want a model for how the data centre operates, capturing essential behaviour while being as *abstract* as possible

Markov Chains
===

Stochastic Models
- May want to capture how a system evolves, using *dependent* random variables, described by some dynamics
- Very simple model is the DTMC, used in...
    - User web page navigation
    - Cache contents and performance
    - Speech recognition
    - Machine learning
    - etc.
- This is also an example of a discrete-time system
- The *n*th "time point" corresponds to the *n*th page visited
- Natural for some settings, but continuous-time framework may be more suitable for others

Discrete-Time Markov Chains (DTMCs)
- A DTMC is a stochastic process $(X_n, n=0, 1, 2, ...)$, where $X_n$ denotes the state at (discrete) time step *n* and such that, $\forall n \geq 0, \forall i, j$ and $\forall i_0, ..., i_{n-1}$:  
$$P(X_n+1 = j | X_n=1, X_{n-1} = i_{n-1}, ..., X_0 = u_0)$$  
$$= P(X_{n+1} = j | X_n = i)$$  
$$= P_{ij}$$
- Last equality is a property known as **stationary**: statistics of process independent of time - $P_{ij}$ is independent of the time step and history
- "Chain" is used since states are "chained" togehter by transitions
- **Markovian Property**: The conditional distribution of any future state $X_{n+1}$, given past states $X_0, X_1, ..., X{n-1}$ and the present state $X_n$ is independent of past states, and **only** depends on the present state $X_n$
- **Transition Probability Matrix**: Associated with any DTMC is a matrix, *P*, whose *i*, *j* entry, $P_{ij}$, represents the probability of moving to state *j* from state *i*
    - *P* may have infinite dimensions, is square, and the rows of *P* should sum to one
    - Also, $P_{ii} \gt 0$ is possible

*n*-step Transition Probabilities
- Let $P^n = P * P ... P$, *n* copies of *P* multipled together
- $P_{ij}^n$: (i, j) entry of $P^n$
- Represents the probability of going from state *i* to *j* in *n* steps
- Calculated with the given probability:  
$$P_{ij}^n = \sum_{k=0}^{M-1} P_{ik}^{m-1} P{kj}$$
- We can also calculate the **limiting probabilities** with this. Let:  
$$\pi_j = \lim_{n \rightarrow \inf} P_{ij}^n$$
- $\pi_j$ represents the limiting probability that the DTMC is in state *j*. For an *M*-state DTMC, with states, 0, 1, ..., *M*-1:  
$$\pi = [\pi_0, \pi_1, ..., \pi_{M-1}]$$  
Also, there is the properties of  
$$\sum_{i=0}^{M-1} \pi_i = 1$$  
$$\pi_j \gt 0$$
- These values can be calculated with the equations:  
$$\pi P = \pi$$  
and  
$$\sum_{i=0}^{M-1} \pi_i = 1$$

Infinite State DTMCs
- Same results hold relating limiting and stationary distributions, only proofs are trickier (interchanging limits and infinite sums have to be done with more care)
- Main issue: Need to solve an infinite number of linear equations for an infinite number of unknowns
- Main case is where there is a probability of *r* for going up a state, a probability of *s* of going down a state, and *1-r-s* of staying in the same state
- If we use $\rho = r/s$, then we can get the equation:  
$$\pi_n = \rho^n(1-\rho)$$  
$$E[N] = \frac{\rho}{1-\rho}$$  

Page Rank Formulas
- **Last Recently Used (LRU)**: Put the last recently used on top of the priority list
- **Move-Ahead**: Move the last recently used up one (1) ranking in priority
- Full example in Lecture 8 Notes

Operational Analysis
===

OA Basics
- A queueing system has a buffer/queue where arriving jobs wait to be served by a server - after being completed, they depat
- A queueing system must describe:
    1. Arrivals - time between arrivals given by a probability distribution
    2. Queue - size (finite or infinite)
    3. How server operates - # of servers, order of service (FCFS, LCFS, etc), processing times in a probability distribution
- Performance indicators include:
    1. Response time - time from arrival to departure
    2. Throughput - # of jobs served per time unit
- Also two possible pieces of analysis directions
    1. Exact analysis - Try to write down equations that yield the desired performance metric, then solve
    2. Simulation - By generating realizations/samples from the underlying distributions, we can follow the logic of the system to estimate the performance measure(s) of interest
- First cut at analytic models, suppose we have the following data:
    - $A_i(t)$ - # of arrivals to device *i* at time *t*
    - $C_i(t)$ - # of completions (departures) from device *i* at time *t*
    - $B_i(t)$ - Busy/processing time of device *i* at time *t*
- From this data, we can quickly get the following values:
    - $\lambda_i(t)$ - Arrival rate at device *i*  
    $$\lambda_i(t) = A_i(t)/t$$
    - $X_i(t)$ - Throughput at device *i*  
    $$X_i(t) = C_i(t) / t$$
    - $\rho_i(t)$ - Utilization of device *i*  
    $$\rho_i(t) = B_i(t)/t$$
    - $S_i(t)$ - Average processing time at device *i*  
    $$S_i(t) = B_i(t)/C_i(t)$$
- NOTE: We will also assume that the system is *ergodic*, meaning the time averages lead to the underlying means. Only thing to note is:  
$$S_i(t) \rightarrow E[S_i] = 1/\mu_i$$

OA Laws
- **Utilization Law**: Given the throughput and average processing time, the utilization of the system can be calculated by:  
$$\rho_i = X_iE[S_i]$$
- **Forced Flow Law**: Suppose $A_i(t) = C_i(t)$ (jobs in = jobs out). Let $E[V_i]$ be the expected number of visits to the device *i* per job. This requires a reference device, which we will call device 0. By definition, $E[V_0] = 1$, so we have:  
$$E[V_i] = \lim_{t \rightarrow \inf} \frac{C_i(t)}{C_0(t)}$$
- Furthermore, if the system throughput *X* is measured through node 0, the throughput of node *i* is then:  
$$X_i = E[V_i]X$$
- Device Demands
    - **Utilization Law**  
    $$\rho_i = X_i E[S_i]$$
    - **Forced Flow Law**  
    $$X_i = E[V_i]X$$
    - Comining the above...  
    $$\rho_i = E[S_i]E[V_i]X$$
    - Average demand at device *i*  
    $$E[D_i] = E[S_i]E[V_i]$$
    - Therefore  
    $$\rho_i = E[D_i]X$$
    - $E[D_i]$ is the expected processing time on device *i* totalled over all visits of a job. The **bottleneck** of a system would be the device with the **highest E[D_i]**
- **Little's Law**: Relates the number of jobs in a queueing system, $E[N_i]$, the arrival rate of the queueing system, $\lambda_i$, and the mean response time, $E[T_i]$  
$$E[N_i] = \lambda_i E[T_i]$$

Users/Clients
- **Users/Clients**: Consider a model where there are *M* users (clients) who operate as follows:
    1. Each user thinks for a period of time thas has mean $E[Z]$ time units (think time)
    2. At the end of a think time, the user submits the job/request to a subsystem
    3. Once procesing is complete at the subsystem (and returned to the user), the user begins another think time
- **General Response Time**: Consider a system with *M* users connected to a subsystem with *K* nodes. We are interested in the mean response time for the subsystem, $E[T]$. Inside the system, the mean number of jobs $E[N]$ satisfies:  
$$E[N] = XE[T]$$  
$$= E[N_1] + E[N_2] + ... + E[N_K]$$  
$$XE[T] = X_1E[T_1] + X_2E[T_2] + ... + X_KE[T_K]$$
$$E[T] = E[V_1]E[T_1] + E[T_2]E[V_2] + .. + E[V_K]E[T_K]$$  
- This gives the final result:  
$$E[T] = \sum_{i=1}^K E[V_i] E[T_i]$$
- **Interactive Response Time Law**: Given the same system, the total mean cycle time of a client's job is $E[Z] + E[T]$. So, in a given time period of length *t*, each client generates on average  
$$\frac{t}{E[Z] + E[T]}$$  
requests
- The throughput is then given by  
$$X = \frac{M}{E[Z] + E[T]}$$  
- The end result gets us  
$$E[T] = \frac{M}{X} - E[Z]$$

Bottlenecking
- **Bottleneck Analysis**: Let $D=E[D_1] + E[D_2] + ... + E[D_K]$ be the average total demand, $D_{\max} = \max_i E[D_i]$ is the maximum demand in the subsystem. We then have  
$$X \leq \min(\frac{1}{D_{\max}}, \frac{M}{D + E[Z]})$$  
$$E[T] \geq \max(D, MD_{\max} - E[Z])$$
- $D_{\max}$ is the "bottleneck demand" and the device which achieves $D_{\max}$ is the "bottleneck"
- The *M* value that matches the left side of the equations for *X* and $E[T]$ is known as the number of clients that the system can support
    - Below this, performance scales well. Above this, performance degrades considerably

OA Equations (letting $t \rightarrow \inf$)  
$X_i$: Throughput of device *i* (jobs/t)   
$X$: Throughput of the system (jobs/t)  
$\lambda_i$: Arrival rate at device *i* (jobs/t)   
$\rho_i$: Utilization of device *i* (%)   
$\mu_i$: Processing rate at device *i* (jobs/t)  
$M$: Number of clients in the system (#)  
$D$: Average total demand (t/jobs)  
$D_{\max}$: Bottleneck demand (t/jobs)  
$E[S_i]$: Average processing time at device *i* (t/request)   
$E[V_i]$: Average expected number of visits to device *i* (request/job)  
$E[D_i]$: Average demand at node *i* (t/jobs)  
$E[N_i]$: Average number of jobs at node *i* (jobs)  
$E[T_i]$: Average response time at node *i* (t)  
$E[Z]$: Average user think time (t)  
//////  
$$E[S_i] = \frac{1}{\mu_i}$$  
$$X_i = E[V_i] X$$  
$$E[D_i] = E[S_i] E[V_i]$$  
$$\rho_i = X_i E[S_i] = E[S_i] E[V_i] X = E[D_i] X$$  
$$E[N_i] = \lambda_i E[T_i]$$  
**Assuming** no wait time, $\lambda_i = X_i$  
$$\text{\# of Requests per Client} = \frac{t}{E[Z] + E[T]}$$  
$$E[T] = \sum_{i=1}^K E[V_i]$$  
$$E[T_i] = \frac{M}{X} - E[Z]$$  
$$D = E[D_1] + E[D_2] + ... + E[D_K]$$  
$$D_{\max} = \max_i E[D_i]$$  
$$X \leq \min (\frac{1}{D_{\max}}, {\frac{M}{D + E[Z]}})$$  
$$E[T] \geq \max (D, MD_{\max} - E[Z])$$  
At the bottleneck, $\rho_{\max} = XD_{\max} \leq 1$  
With one client, $E[T] = E[D_1] + ... + E[D_K] = D \rightarrow E[T] \geq D$  
$$E[T] = \frac{M}{X} - E[Z] \geq MD_{\max} - E[Z]$$  
$$X = \frac{M}{E[Z] + E[T]} \leq \frac{M}{E[Z] + D}$$ 


Exponential Distribution and Poisson Process
===

Exponential Distribution
- REMEMBER: Exponential distirbution follows the memoryless property, meaning that any amount of time that has passed does not change the possible outcome based on the current state:  
$$P(X \gt s + t | X \gt s) = P(X \gt t)$$
- **Property 1**: Given $X_1 ~ Exp(\lambda_1)$, $X_2 ~ Exp(\lambda_2)$, and $X_1, X_2$ are independent, then:  
$$P(X_1 \lt X_2) = \frac{\lambda_1}{\lambda_1 + \lambda_2}$$
- **Property 2**: Given $X_1 ~ Exp(\lambda_1)$, $X_2 ~ Exp(\lambda_2)$, and $X_1, X_2$ are independent, then:  
$$X = min(X_1, X_2) ~ Exp(\lambda_1 + \lambda_2)$$
- Counting Process: Let $N(t)$ be a counting process:
    1. $N(t)$ is nondecreasing
    2. $N(t) = 0,1,2,...$
    - $N(t)$ counts *events* - ie. arrivals
- **Independent Increments**: A process has independent increments if for non-overlapping time intervals $(t_0, t_1), (t_2, t_3), (t_4, t_5), ..., (t_{2n}, t_{2n+1})$, we have:  
$$P(N(t_1) - N(t_0) = k_0, N(t_3) - N(t_2) = k_1, ..., N(t_{2n+1}) - N(t_0{2n} = k_n)$$  
$$=P(N(t_1) - N(t_0) = k_0) * P(N(t_3) - N(t_2) = k_1) * ...$$
- **Stationary Increments**: A process has stationary increments if $\forall s \geq 0$:  
$$P(N(t+s) - N(s) = k) = P(N(t) = k)$$

Exponential Distribution Equations  
$$P(X = a) = \lambda e^{-\lambda a}$$  
$$P(X \leq a) = 1 - e^{-\lambda a}$$  
$$P(a \leq X \leq b) = \int_a^b \lambda e^{-\lambda x} dx$$  
$$P(a \lt b, c) = \frac{\lambda_a}{\lambda_a + \lambda_b + \lambda_c}$$  
$$E[X] = \frac{1}{\lambda_a + \lambda_b + \lambda_c}$$  
$$V(X) = \frac{1}{(\lambda_a + \lambda_b + \lambda_c)^2}$$   

Poisson Process
- **Definition 1**: A poisson process with rate $\lambda$ is a counting process such that:
    1. $N(0) = 0$
    2. The process has independent increments
    3. The number of events in any interval of length *t* is Poisson distributed with mean $\lambda t$. That is, $\forall s, t \geq 0$:  
    $$P(N(t+s) - N(s) = k) = \frac{(e^{-\lambda t})(\lambda t)^k}{k!}, k = 0, 1, ...$$
- **Definition 2**: A Poisson process with rate $\lambda$ is a counting process such that the interarrival times are independent and identially distributed (i.i.d.) exponential random variables with rate $\lambda$ and $N(0) = 0$
- Note, these two definitions are equivalent
- **Merging Poisson Processes**: Given two independent Poisson processes, where process 1 has rate $\lambda_1$ and process 2 has rate $\lambda_2$, the merge of process 1 and process 2 is a single Poisson process with rate $\lambda_1 + \lambda_2$
- **Splitting a Poisson Process**: Given a Poisson process with rate $\lambda$, suppose that each event is classified as "type A" with probability *p* and "type B" with probability $1-p$. Then type A events form a poisson process with rate $p \lambda$, type B events form a Poisson process with rate $(1-p)\lambda$, and these two processes are **independent**. Specifically, if $N_A(t)$ denotes the number of type A events by time t, and $N_B(t)$ denotes the number of type B events by time t, then:  
$$P(N_A(t) = n, N_B(t) = m) = P(N_A(t) = n) * P(N_B(t) = m)$$  
$$= e^{-\lambda t p} \frac{(\lambda t p)^n}{n!} e^{-\lambda t (1-p)} \frac{(\lambda t (1-p))^m}{m!}$$
- **Event Theorem**: Given that one event of a Poisson process has occurred by time *t*, the event is equally likely to have occurred anywhere in $[0, t)$

Poisson Process Equations  
$$P(N_x(t_2) - N_x(t_1) = k) = \frac{(e^{-\lambda t})(\lambda t)^k}{k!}, k = 0, 1, ...$$  
$$P(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}, k = 0, 1, 2, ...$$  
$$E[X] = V(X) = \lambda$$  
- Note that arrivals **always** come in an exponential distribution with the same rate of the Poisson process

Continuous-Time Markov Chains
===

CTMC's
- DTMCs have transitions made only at discrete time steps. This generalizes to transitions that can happen at *any time*, but keep the state space countable (discrete)
- **CTMC Definition**: A CTMC is a continuous-time stochastic process $(X(t), t \geq 0)$, such that $\forall s, t \geq 0$ and $\forall i, j, x(u)$  
$$P(X(t+s) = j | X(s) = i, X(u) = x(u), 0 \leq u \leq s)$$  
$$= P(X(t+s) = k | X(s) = i)$$  
(^ by Markov property)  
$$= P(X(t) = j | X(0) = i) = P_{ji}(t)$$  
(^ by stationary)
- **Residence Times**: Define $\tau_i$ to be the time until the CTMC leaves state *i*, given that the CTMC is currently in state *i*. Must have:  
$$P(\tau_i \gt t + s | \tau_i \gt s) = P(\tau_i \gt t)$$  
But this means that $\tau_i$ is exponentially distributed
- **Limiting Probabilities**: Would like to solve for  
$$\pi_j = \lim_{t \rightarrow \inf} P_{ij}(t)$$  
the limiting probability of being in state *j*
- We calculate this by the rate of transitions into a state equal to the rate of transitions out of a state, ex:  
$$\pi_i(0.3 + 0.5) = (0.25)\pi_0 + (0.4)\pi_2$$
    - We also get the usual sum to 1 equation
    - There equations are known as the **global balance equations**

M/M/1 Queue
- Has the following properties:
    - Single server
    - Arrivals follow a Poisson process with rate $\lambda$
    - Processing/service times follow $Exp(\mu)$ distribution (hence, mean is $1/\mu$)
    - Infinite waiting room
- Let $X(t)$ be the number of jobs in the system at time *t*. The global balance equations are given as:  
$$\lambda \pi_0 = \mu \pi_1$$  
$$(\lambda + \mu) \pi_n = \lambda \pi_{n-1} + \mu \pi_{n+1}, n \geq 1$$
- This solves to the following:  
$$\pi_n = (\frac{\lambda}{\mu})^n \pi_0$$
- Also, given the **utilization/load** of the system as $\rho = \lambda / \mu \lt 1$, and the probability that a server is busy is $1-\pi_0 = \rho$, we get the following:  
$$\pi_0 = 1-\rho$$  
$$\pi_n = (1-\rho) \rho^n$$
- We can also get the following values:  
$$E[N] = \frac{\rho}{1 - \rho}$$  
$$E[T] = \frac{1}{\mu - \lambda}$$
- **Birth-Death Process**: Suppose that $\lambda_n$ is the rate out of state $n$ to $n+1$, and $\mu_n$ is the rate out of $n$ to state $n-1$. This is known as the "Birth-Death Process", the $\lambda$ values are the birth rates and the $\mu$ values are the death rates
- General solution to a birth-death process:  
$$\pi_n = \frac{\lambda_0\lambda_1 ... \lambda_{n-1}}{\mu_1\mu_2 ... \mu_n} \pi_0$$  
$$\pi_0 = \frac{1}{1 + \sum_{n=1}^{\inf} \Pi_{i=1}^n \frac{\lambda_{i-1}}{\mu_i}}$$
- **Little's Law** applies here too, relating the number of jobs in a queueing system, $E[N]$, the arrival rate of the queueing system, $\lambda$, and the mean response time, $E[T]$  
$$E[N] = \lambda E[T]$$

M/M/1/*N* Finite Buffer System
- Same as M/M/1, but arriving jobs (beyond *N* in system) are "lost" or "blocked", not returning at a later time
- Gives us the equations:  
$$\pi_n = (\frac{\lambda}{\mu})^n \pi_0, n=0, 1, ..., N$$  
$$\pi_0 = 1/\sum_{n=0}^N (\lambda/\mu)^n$$  
$$E[N] = \sum_{n=0}^{N} n\pi_n$$
- **Blocking probability** is the probability that the system is full calculated by the steady state of $\pi_N$  
    - Mean number of jobs lost per unit time is then $$\lambda \pi_N$$
    - The actual arrival rate of a system with a blocking probability $\pi_N$ (which can also be seen as throughput) can be calculated as well as $\lambda' = \lambda (1 - \pi_N)$

M/M/Inf Queue
- Each job is now immediately assigned its own processor (or each job its own server)
- Gives us the equations:  
$$\pi_n = \frac{1}{n!} (\frac{\lambda}{\mu})^n \pi_0$$  
$$\pi_0 = e^{-\lambda / \mu}$$
- Final limiting distribution is:  
$$\pi_n = \frac{1}{n!} (\frac{\lambda}{\mu})^n e^{-\lambda / \mu}$$
    - $E[N] = \lambda / \mu$
    - $E[T] = 1/\mu$

M/M/*c* Queue
- *c* processors in parallel and a queue for waiting jobs  
$$\pi_n = \frac{1}{n!} (\frac{\lambda}{\mu})^n \pi_0, n = 0, ..., c-1$$  
$$\pi_0 = [1 + \sum_{n=1}^{c-1} \frac{1}{n!} (\frac{\lambda}{\mu})^n + \frac{1}{c!} (\frac{\lambda}{\mu})^c (\frac{1}{1-\rho})]^{-1}$$
- Where $\rho = \frac{\lambda}{c \mu}$
- Further equations:  
$$E[N_Q] = [\frac{(\lambda/\mu)^c \lambda \mu}{(c-1)!(c\mu - \lambda)^2}] \pi_0$$  
$$E[T_Q] = [\frac{(\lambda/\mu)^c \mu}{(c-1)!(c\mu - \lambda)^2}] \pi_0$$  
$$E[T] = \frac{1}{\mu} + [\frac{(\lambda/\mu)^c \mu}{(c-1)!(c\mu - \lambda)^2}] \pi_0$$  
$$E[N] = \lambda E[T]$$
- **Erlang-C Formula**  
$$P(queueing) = \sum_{n=c}^{\inf} \pi_n$$  
This sum evaluates to:  
$$\frac{1}{c!} (\lambda / \mu)^c(1/(1-\rho)) \pi_0$$

M/M/*c*/*c* Queue

Client/Server Model


Multiserver/Network of Queue Systems
===

System Comparison
- Comparing the following three systems
    1. k queues and k server systems
    2. 1 queue and 1 server systems
    3. 1 queue and k server systems
- 3 is preferred over 1
    - System 1 has the case where servers are sitting idle and the others have more than one job, where System 3 cannot run into that
- 2 is preferred over 3
    - Only difference is instead of having k servers like in 3, 2 has one server working at $k\mu$ capacity
    - 2 is preferred since the maximum processing speed of 3 is $k * \mu $, when all servers are running, but the minimum processing time for system 2 is $k * \mu$
- This gives us the order:  
    $$S_2 \gt S_3 \gt S_1$$

*k* M/M/1 (1) vs M/M/1 (2)
- For the fast M/M/1 system and one of the *k* slow M/M/1 queues, the number in system is the same, as both the arrival rate and processing rate are scaled up by a factor of *k* in the fast M/M/1 system  
$$E[T^{(1)}] = \frac{1}{\mu - \lambda/k} = \frac{k}{k\mu - \lambda}$$  
$$E[T^{(2))}] = \frac{1}{k\mu - \lambda}$$
    - Note, although this is good in theory, this is not good in practice. Replacing *k* servers with one server would be exponentially expensive, if possible, and would create a lot of heat and more issues. If this server went down, this can become a much larger issue than just one of the *k* servers going down

M/M/1 (2) vs M/M/k (3)
- For the M/M/k system:  
$$E[N_Q] = E[N_Q | \text{queueing}] P_Q$$  
(The expected number in queue is the expected number in queue given that jobs are queueing multiplied by the probability of queueing)
$$E[N_Q] = \frac{\rho}{1-\rho} P_Q$$
$$E[T] = \frac{1}{\lambda}P_Q\frac{\rho}{1-\rho} + \frac{1}{\mu}$$
$$\frac{E[T^{(3)}]}{E[T^{(2)}]} = \frac{\frac{1}{\lambda}P_Q\frac{\rho}{1-\rho} + \frac{1}{\mu}}{\frac{1}{\lambda}\frac{\rho}{1-\rho}}$$  
$$= P_Q + \frac{\lambda}{\mu}\frac{\rho}{1-\rho}$$  
$$= P_Q + k(1-\rho)$$  
- Note the following:
    1. $\rho \approx 0$ gives $P_Q \approx 0$, so the M/M/1 is *k* times faster
    2. $\rho \approx 1$ gives $P_Q \approx 1$, so the two systems perform the same

Capacity Provisioning
- For an M/M/*k* system:  
$$E[T_Q] = \frac{1}{\lambda} P_Q \frac\rho{1-\rho}$$  
where $\rho = \lambda/k\mu$
- $$E[T_Q] = E[T_Q \| delayed]P_Q + E[T_Q \| not delayed](1-P_Q)$$  
$$= E[T_Q \| delayed]P_Q$$  
$$\frac{E[T_Q]}{P_Q} = E[T_Q \| delayed]$$
- Expected waiting for those jobs that are delayedL  
$$\frac{E[T_Q]}{P_Q} = \frac1\lambda * \frac\rho{1-\rho} = \frac1{k\mu(1-\rho)}$$
- When $\rho$ is fixed, this is a decreasing function of *k*
    - For high values of $\rho$, jobs will not necessary suffer provided there are sufficiently many servers
- **Capacity Provisioning Rule**: For an M/M/*k* queue with arrival rate $\lambda$ and processing rate $\mu$, the quantity $R = \lambda/\mu$ is equivalently:
    1. Minimum number of servers needed to keep system stable
    2. Expected number of busy servers
    3. Expected number of jobs being processed
- If *R* is large, then $k = R + \sqrt{R}$ yields $P_Q \lt 20\%$
- For an M/M/$\infty$ queue, arrival rate $Poisson(R)$ will be approximated by $Normal(R,R)$, thus the probability of more than $R + \sqrt{R}$ is the probability that the $Normal(R,R)$ is more than one standard deviation above its mean, 0.16
    - M/M/$\infty$ is a lower bound, as the fraction of time it has more than *x* servers busy is lower than the fraction of time that an M/M/*k* has more than *x* servers busy
- **Theorem**: Given an M/M/*k* with arrival rate $\lambda$ and server speed $\mu$ and $R = \lambda/\mu$, where *R* is large, let $ k_\alpha^{*} $ denote the least number of servers needed to ensure that $P_Q^{M/M/k} \lt \alpha$. Then:  
$$k_\alpha^* \approx R + c \sqrt{R}$$  
where *c* solves:  
$$\frac{c \Phi(c)}{\phi(c)} = \frac{1 - \alpha}\alpha$$  
where $Phi(c)$ is the cdf of a Normal(0,1) and $\phi(c)$ is its density

Open Networks
- All arriving jobs eventually leave the system
- External arrivals follow a Poisson process with rate $r_i$ to node *i*
    - Each node has an infinite buffer and a single server, processing times exponentially distributed with rate $\mu_i$
- **Routing**: Job exiting node *i* goes to node *j* with probability $P_{ij}$
- **Traffic Equations**: Equations for the arrival rate to node *i* (if the system were stable):  
$$\lambda_i = r_i + \sum_{j = 1}^N P_{ji} \lambda_j, i = 1, 2, ..., N$$
- **Limiting Distribution**: The following solution to the balancing equations:  
$$\pi_{\bar{n}} = \Pi_{i=1}^N \pi_{n_i}^i$$  
$$\pi_{n_i}^i = \left(1 - \frac{\lambda_i}{\mu_i} \right) \left( \frac{\lambda_i}{\mu_i} \right)^{n_i}$$
- **Product-Form Solution**: Probabilities are a product of quantities at one queue only, suggests that queues are "independent" of one another
- **Bottleneck Analysis**: Bottleneck is node with largest load (consistent with OA)

Closed Networks
- *M* jobs in the system - none leave, no more enter
- $r_i = 0, \sum_{j=1}^N P_{ij} = 1$
- **Traffic Equations**:  
$$\lambda_i = \sum_{j=1}^N P_{ji} \lambda_j$$
- Note, there is **no unique solution to this set of equations**, but  can still use any valid (nonzero) solution:  
$$\pi_{\bar{n}} = C \Pi_{i = 1}^N \left( \frac{\lambda_i}{\mu_i} \right)^{n_i}$$  
we need to calculate *C* though, AAA (TODO)

Mean Value Analysis
- For a closed network, we know that:  
$$\pi_{\bar{n}} = C \pi_1 (n_1) \pi_2 (n_2) ... \pi_N (n_N)$$  
where:  
$$\pi_i (n_i) = \left( \frac{\lambda_i}{\mu_i} \right)^{n_i}$$  
and $\lambda_i$ is the solution to the traffic equation above
- This would pose a very difficult task for computing *C*, so we use the following equations for mean response time, throughput, and number of jobs at node *i* with *m* jobs in the network:  
$$E[T_i^{(m)}] = \frac1{\mu_i} + \frac1{\mu_i} E[N_i^{(m-1)}]$$  
$$X(m) = \frac{m}{Z + \sum_{i=1}^N V_i E[T_i^{(m)}]}$$  
$$E[N_i^(m)] = E[T_i^{(m)}] V_i X$$  
where $V_i$ is the visit ratio to node *i*. Letting the user node be node 0 and setting $V_0 = 1$, we can calculate the others with:  
$$V_i = \sum_{j=0}^N V_j P_{ji}$$

Simulation
===

Random Number Generation (RNG)
- **Pseudo Random Number Generation (PRNG)**: Computers cannot generate truly random numbers, use a sequency of pseudo random numbers, passing statistical tests of randomness but will repeat after enough iterations
- Essentially generates samples from $U[0,1]$, dependent on seed for where to start in the iteration

Samples from a Given Distribution
- Suppose we're only able to generate sample from a $U[0,1]$ distribution. How do we generate samples from some other distribution that we would like to use in our simulation?
- **Discrete Case**: Generate a sample *x* from a DRV *X* having pmf $P(X = x_j) = p_j$
    - $(x_j)$ is a finite set of numbers, and can be fetched by generating a sample *u* from $U[0,1]$. If $u \lt p_1$, set $x = x_1$. If $u \lt p_1 + p_2$, set $x = x_2$. Continue for all numbers in set
- **Continuous Case**: We want to map a CRV of $U[0,1]$ to $F(x)$:  
$$u = P(0 \lt U \leq u) = P(0 \lt X \leq x) = F(x)$$  
so $x = F^{-1}(u)$
    - F(x) is an exponential distribution with rate $\lambda$, which gives us:  
    $$F^{-1}(u) = -ln(u)/\lambda$$  
    - NOTE: $1-u$ is replaced with $u$ since both are samples from $U[0,1]$

Simulation Construction
- **Discrete Event Simulation** has the following general structure:
    1. Time Variable *t*: elapsed (simulated) time
    2. Counter Variables: track the number of times that certain events have occurred (by time *t*)
    3. State Variables: "state" of the system at time *t*, chosen such that the next state can be uniquely determined given any event occurrence
    4. Output Variables
- Whenever an event occurs, values of variables must be updated
- Example of two single-server queues in series would have events for
    1. Arrival to system
    2. Departure from Q1
    3. Departure from Q2
    - Each event would update time, state, and time till next events

Confidence Intervals
- Used to compute "how good" an estimate is for a population based on sample data:  
$$P(a \leq E[X] \leq b) = 1 - \alpha$$  
where $\alpha$ is the significance level, $(a,b)$ is the confidence interval, and $100(1 - \alpha)$ is the confidence level (usually close to 100%)
- Using *t*-distributions for this class, finding $t_{1-\alpha/2, n-1}$: the $1 - \alpha/2$ quantile of the *t*-statistic with $n-1$ degrees of freedom
- For a mean value, we would use:  
$$\bar{X} \pm \frac{t_{1-\alpha/2, n-1} s}{\sqrt{n}}$$  
where the sample variance $s^2$ is given as:  
$$s^2 = \frac1{n-1} \sum_{i=1}^n (x_i - \bar{X})^2$$

Output Analysis
- Initial transient response of a system could potentially bias the results, remedies include:
    1. Discard the first *k* observations, for some suitably chosen value of *k*
    2. Eyeball results and do transient removal ad hoc
    3. Simulate so long that the effect is negligible
- Can also use **independent replicas** to alleviate this, repeating the simulation *N* times each time using a different seed, and using transient removal on each result
- **Batch Means** takes one run with observations $(x_i)$, transient removal removes the first *k* observations, and then break up the remaining observations into *s* batches of size *r*, where $s = (n-k)/r$ is an integral
- We calculate $Y_j$ as the average of the *j*th batch, treating the values as if they were independent:  
$$Y_j = \frac{1}{r} \sum_{i = k + (j-1)r + 1}^{k + jr} x_i, j = 1, ..., s$$

Model Validation
- Check simulation is implementing the correct model
    1. **Expert Intuition**: Domain expert validates input and output
    2. **Real System Measurements**: Most reliable and preferred way, compare results to real life measurements with similar inputs and outputs
    3. **Theoretical Results**: Make assumptions for a system that cannot be exactly analyzed to examine results, *partial validation*


Reliability
===

Time-Independent Reliabilities
- System composed of components such that when we examine the system, component *i* is working with probability $R_i$. Components fail independently of other components
- **Components in Series**: The system is working if *all* of its components are working:  
$$R = R_1 * R_2 * ...$$
- **Components in Parallel**: The system is working if *at least one* of its components is working, or it fails if all have failed:  
$$R = 1 - (1 - R_1)(1 - R_2) ...$$
- **Triple Modular Redundancy**: System consists with three components, each having the same reliability:  
$$R_{TMR} = R^3 + \binom32 R^2 (1-R)$$

Redundancy
- Concept of adding a *redundant* component in parallel with a component originally in series to improve reliability
    - Redundant component is working with same probability as original component
    - Would change a system probability like the following:  
    $$R = (0.95)(0.9)(0.95) = 0.81$$
    $$R - (0.95)(0.9)(1 - (1 - 0.95)^2) = 0.8529$$
    - Best to add onto the **least reliable piece** of a system

Time-Dependent Reliabilities
- Deals with concepts like how long a system will operate before failure, and if they can become more/less likely to fail as time progresses 
- **Lifetime**: *X* is a random variable that represents the lifetime of a component/system, with distribution $F(x)$ and density $f(x)$
    - $f(t) \Delta t$ is approximately the probability that a failure occurs in the interval $(t, t + \Delta t]$
- The conditional likelihood of failure:  
$P(X \leq t + x | X \gt t) = \frac{P(t \lt X \leq t + x)}{P(X \gt t)} = \frac{F(t + x) - F(t)}{1 - F(t)}$$
- The instantaneous failure rate ($h(t) \Delta t$ is the conditional probability that a component that has survived to age *t* will fail in the interval $(t, t + \Delta t]$):  
$$h(t) = \frac{f(t)}{1 - F(t)}$$
- If you are given $h(t)$ rather than $F(t)$, you can still use the notation for $R(t) = P(X \gt t)$ to get:  
$$R(t) = \exp \left[ - \int_0^t h(x) dx \right]$$   
$$F(t) = 1 - R(t)$$
- **Rated Lifetime**: The age that 90% of components are expected to exceed
    - If *L* is the rated lifetime, then $F(L) = 0.1$

Failure Rate
- **Increasing Failure Rate (IFR)**: $h(t)$ is a nondecreasing function of *t*, more likely to fail as they age
    - May be desirable to replace a component before it fails
- **Decreasing Failure Rate (DFR)**: $h(t)$ is a nonincreasing function of *t*, less likely to fail as they age
    - **Never** preemptively replace a component
- Distributions can be neither of the above, usually following a *"bathtub curve"*, where the range that the failure rate is constant is often the useful life
- **Constant Failure Rate**: Failure corresponds to an exponential distribution
    - CTMC approac h is applicable for this

Machine Repair Problem
- *N* machines, each failing independently with rate $\lambda$, *M* servers for repairs, each working on a single machine with repair rate $\mu$
    - Birth-death process processed as in CTMC material
- **Mean Time to Failure (MTTF)**: Average time for the system to fail
    - Take state 0 as the initial state, and state *N* as the final state. MTTF is the time to go between state 0 and *N*. For each $j = 0, ..., N-1$, write:  
    $$E[T_{j,N}] = 1/\gamma_j + \sum_{k=0}^{N-1} P_{j,k} E[T_{k,N}]$$
    - Get a system of *N* equations and *N* unknowns, looking for $E[T_{0,N}]$

Scheduling and the Impact of Variability
===

M/G/1 Queue
- Arrivals follow a Poisson process with rate $\lambda$, processing times follow a general distribution, mean $1/\mu$ and second moment $E[S^2]$, processing is FCFS
    - Large $E[S^2]$ would make it more likely to see a big job being processed than one of the smaller jobs
- Response time can be given by the Pollaczek-Khinchin formula:  
$$E[T] = \frac{\lambda E[S^2]}{2(1 - \rho)} + \frac1\mu$$
    - Performance degrades proportionately with second moment (and hence variance)
    - When $\rho$ is close to 1, the impact of $\rho$ is still the most significant factor
- Can rewrite for variance of processing times $\sigma_S^2$:  
$$E[T] = \sigma_S^2 * \frac{\lambda}{2(1 - \rho)} + \frac1\mu * \frac{2 - \rho}{2(1 - \rho)}$$
- Reducing variability is worth looking into, and reducing mean processing time is not always beneficial if side effect is increased variability

Scheduling
- Move away from FCFS to improve performance
- **Processor Sharing (PS)**: If there are *n* jobs at the processor, it (virtually) splits itself into *n* processors, each working at rate $\mu/n$:  
$$E[T] = \frac{1/\mu}{1 - \rho}$$
    - No more dependence on variance, preferred if variance is large
    - If processing times less valuable than an exponential distribution, FCFS preferred
- **Preemptive LCFS**: (Preemptive) priority if given to the most recently arrived job:  
$$E[T] = \frac{1/\mu}{1 - \rho}$$
    - Arriving small jobs don't get stuck behind large jobs. Large jobs may preempt small jobs, but the probability for this is very small
- **Shortest Remaining Processing Time (SRPT)**: Processing times known upon arrival, minimize number of jobs in the system at every point of time
    - Minimizes the expected number of jobs in system and mean response time as a result


Routing and Load Balancing
===

Routing/Load Balancing Methods
- We will be working with the simplest system, assuming arrivals follow a Poisson process with rate $\lambda$, *N* servers in parallel, and processing times at each server exponentially distributed with rate $\mu$
    - Routing decisions **must** be made upon arrival of a job
- **Random Routing**: Route to each server with probability $1/N$, resulting in *N* M/M/1 queues
- **Round Robin**: Assign jobs to servers in the order of $1, 2, ..., N, 1, 2, ..., N, 1, 2, ...$, minimizing interarrival times to queues
    - Both of the above balance in a "long term" sense, and don't need to know any information about the backend servers
- **Join the Shortest Queue (JSQ)**: Assuming the load balancer knows the current queue lengths at all servers, send arrival to the shortest queue (breaks ties randomly)
    - As system load goes to 1 ($\lambda$ approaches $N \mu$), the mean response time approaches that of an M/M/*N* queue, best possible solution
    - Requires huge amount of communication overhead however
- Could get servers to signal load balancer when they are idle, reducing overhead, system sends to an idle server, otherwise does random
    - Still results in M/M/*N*


Misc End Course Content
===

Linux Kernel Model
- Jobs at the CPU can be in one of three contexts:
    1. User context - executing user code
    2. Kernel context - executing OS code
    3. Driver context - executing driver code
- Kernel jobs enter in kernel context, and user jobs enter in user context, processing to kernel context
    - From kernel context, jobs can:
        1. Enter user context $(p_{user})$
        2. Enter driver context $(p_{io})$
        3. Complete processing $(p_{done} = 1 - p_{user} - p_{io})$
    - From driver context, jobs can:
        1. Enter kernel context $(p_{drivedone})$
        2. Enter I/O context $(1 - p_{drivedone})$
    - From I/O context, jobs always enter driver context
- Linux kernel prioritizes driver > kernel > user
    - User context preempted by other two contexts
    - Kernel context **cannot** be preempted by the driver context
    - Driver/kernel context have much shorter processing times, avoid being blocked by larger user jobs
    - Driver context is highest priority so the disk is provided jobs in a timely manner
- Can model with a CTMC, with a state of four entries:
    1. number of jobs in driver context
    2. number of jobs in kernel context
    3. number of jobs in user context
    4. (if necessary) a flag that indicates if a job in kernel/driver context is done executing

Thread Pool Management
- Closed network with a single CPU and *n* resources (disks, etc.)
    - Demand known: $E[D_0]$ (CPU) and $E[D_i], i = 1, ..., n$
    - With *M* jobs in the network, can calculate throughput and mean response time using MVA
- An arrival to the server that sees all threads occupied is rejected
- How many threads should be in the thread pool?
    - Choose *M* to maximize throughput (minimize rejection probability) subject to a constraint on the mean response time
    - Keep increasing *M* until $E[T] \gt C$ ($E[T] \leq C$ is the performance requirement), call the resulting value of M, $M^*$
        - Simply choose $M^* - 1$
- As number of threads increases, amount of memory assigned to each thread decreases, thrashing may become frequent and results in demands increasing
    - Typically demands are constant up to some number of threads $\bar{M}$, then they begin to increase
- Simple solution is to not allow more than $\bar{M}$ threads, choose a number of threads to be:  
$$\min(M^* - 1, \bar{M})$$

Software Bottlenecks
- Where physical resources do not reach 100% utilization, but software resource limits performance
    - Difficult to predict, would require analysis of system

Request Replication
- **Replication Model**: Send multiple requests simultaneously, kill when one completes
- Pros and Cons:
    - Data must be replicated
    - Overhead of killing jobs
    - Resource wastage?
    - Do noe need to know queue lengths (compared to JSQ)
    - Has been shown to improve performance
- Network model as two servers, rates $\mu_1, \mu_2$, arrivals to node 2 at rate $\lambda_A$, replicated arrivals (both nodes) at rate $\lambda_R$
- For a CTMC, state would be central queue of jobs in system, ordered w/r/t arrival times
    - Steady state probability of being in state $(c_n, c_{n-1}, ..., c_1)$ is:  
    $$\pi_{(c_n,...,c_1)} = C_N \left( \frac{\lambda_A}{\mu_2} \right)^{a_0} \left( \frac{\lambda_R}{\mu_1 + \mu_2} \right)^r \left( \frac{\lambda_A}{\mu_1 + \mu_2} \right)^{a_1}$$  
        - $a_0$: number of class *A* jobs before the first *R* job
        - $a_1$: number of class *A* jobs after the first class *R* job
        - *r*: number of class *R* jobs
    - $$C_N = \frac{(\mu_2 - \lambda_A)(\mu_1 + \mu_2 - \lambda_A + \lambda_R)}{\mu_2(\mu_1 + \mu_2 - \lambda_A)}$$
- Response time of class *R* jobs is $Exp(\mu_1 + \mu_2 - \lambda_A - \lambda_R)$
    - Compared with two M/M/1's, one for each class, with $\mu_1 = \mu_2$ and $\lambda_A = \lambda_R$, class *R* improves $E[T]$ by a factor of 2, and class *A* hurt by up to 50% (often less than that)
    - If class A becomes redundant, class *R* is unaffected, of course improvement for class *A* (system becomes an M/M/1)
- Overall, redundancy better than JSQ, often for both classes