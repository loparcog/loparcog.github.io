---
layout: post
title:  "4E03 - Lecture 12"
date:   2020-10-05 16:30:00 -0400
categories: 4E03
---

Further Poisson Process
===

Recall...
- Poisson Process
    - Definition 1: A poisson process with rate $\lambda$ is a counting process such that:
    1. $N(0) = 0$
    2. The process has independent increments
    3. The number of events in any interval of length *t* is Poisson distributed with mean $\lambda t$. That is, $\forall s, t \geq 0$  

    $$P(N(t+s) - N(s) = k) = \frac{e^{-\lambda t}(\lambda t)^k}{k!}, k=0, 1, ...$$

    - Definition 2: A poisson process with rate $\lambda$ is a counting process such that the interarrival times are *independent and identically distributed* (IID) exponential random variables with rate $\lambda$ and $N(0) = 0$

Continuing
- The two definitions are equivalent
- Definition 1 implies Definition 2 is easy to show
    - Other way around is quite difficult
- **Merging Poisson Processes**: Given two independent Poisson processes, where process 1 has rate $\lambda_1$, and process 2 has rate $\lambda_2$, the merge of process 1 and 2 is a single poisson process with rate $\lambda_1 + \lambda_2$
    - The time to the first event is the time to the minimum of the first event from each process. Let these be $X_1$ and $X_2$, therefore:  
    $$\min(X_1,X_2) \approx Exp(\lambda_1 + \lambda2)$$
- This can also work backwards, through **Splitting/Thinning a Poisson Process**
    - Given a poisson process with rate $\lambda$, suppose each event is classified as "type A" with possibility *p* and "type B" with possibility *1-p*. Then type A events form a poisson process with rate $p\lambda$ and type B with rate $(p-1)\lambda$, and the two processes are independent.
- Given that exactly one event of a Poisson process has occurred by time *t*, that event is equally likely to have occurred anywhere in $[0, t)$
    - In other words, there's a uniform distribution on the occurrence of this event

Ex: Requests arrive to a web server in the following manner: Requests for domain *a.com* arrive according to a Poisson process with rate 4/min, while requests for *b.com* arrive according to a Poisson process with rate 6/min. The two processes are independent.
- a) What is the expected time of the next arrival?  
SOLN:  
We don't care if it's *a.com* or *b.com*, so we should look at combined arrivals, merging the poisson processes, giving us a new rate of 10/min.  
The time to the next arrival is then $Exp(10)$, and the mean is $\frac{1}{10}$ minutes, which is also 6 seconds.
- b) Of the first 10 arrivals, what is the probability exactly 4 of them are for *a.com*  
SOLN:  
The probability an arrival is for *a,com* is given as its rate over the total rate:  
$$P(\text{arrival is for a.com}) = \frac{4}{4+6} = 0.4$$  
Can then use a binomial distribution to solve this:  
$$P(X=4)=\binom{10}{4}(0.4)^4(0.6)^6$$  
- c) The last *a.com* arrival was 10s ago, and the last *b.com* arrival was 15s ago. What is the expected time to the next *a.com* arrival?  
SOLN:  
None of this data matters because of the memoryless property, and we know that the rate ia 4/min, so we know the next one will come in $\frac{1}{4}$ minutes

From DTMCs to CTMCs
- For DTMCs, transitions are only made at discrete time steps. We want to generalize transitions to be able to happen anytime
    - Don't get confused with having infinite states, that is not a CTMC
- A **Continuous-Time Markov Chain (CTMC)** is a continuous-time stochastic process $[X(t), t \geq 0]$ such that $\forall s, t \geq 0$, and $\forall i, j, x(u),$  
$$P(X(t+s) = j|X(s) = i, X(u) = x(u), 0 \leq u \leq s)$$  
$$= P(X(t+s) = j|X(s) = 1)$$  
$$= P(X_t+=j|X(0)=1)$$
AAA (finisdh)
The first equality is the Markov property and the second is stationary
    - This also gives it the memoryless property
- Residence Times
    - Define $\tau_i$ to be the time until the CTMC leaves state *i*, given that the CTMC is currently in state *i*. Must have:  
    AAA(finish)  

Ex2: Consider a server system with a single backup. The time to failure is exponentially distributed with mean 86.4hrs and repair times are exponentially distributed with mean 2.5hrs. When a server is failed, a backup server is (instantaneously) started. This server is identical in failure/repair characteristics. A server can only fail when operating.
- CTMC Model - Construction 1
    - States: 0 (server operating, other server ready); 1 (server operating, other server failed); 2 (both servers failed)
    - Time spent in state 0: $Exp(\frac{1}{86.4})$. The next state is 1 with probability 1
    - Time spent in state 1: $Exp(\frac{1}{86.4} + \frac{1}{2.5})$. The next state is 0 with probability $\frac{86.4}{88.9}$, otherwise it is state 2
    - Time spent in state 2: $Exp(\frac{1}{2.5} + \frac{1}{2.5})$. The next state is 1 with probability 1.  
        - So, time spent in state $i \approx Exp(v_i)$, upon exit go to state *j* with probability $P_{ij}$
        - Also note, no two events can occur simultaneously
- CTMC Model - Construction 2
    - Lets look @ state 1
    - Start two clocks, with timeouts given by $Exp(\frac{1}{86.4})$ and $Exp(\frac{1}{2.5})$. Whichever times out first makes the corresponding transition.
    - Summarize this information in a *transition rate diagram* (given in lecture)  
    AAA (img)
    - The two model constructions are equivalent
- Limiting Probabilities
    - We would like to solve for:  
    $$\pi_j = \lim_{t \rightarrow \inf} P_{ij}(t)$$  
    the limiting probability of being in state j
    - One approach (in book) - convert to a DTMC problem and solve
    - Other approach - we know that the number of transitions into state 1 differs from the number of transitions out of state 1 by at most one
        - We will use this approach
        - Want to look for the # of transitions into the state to be the same as the # of transitions out of the state