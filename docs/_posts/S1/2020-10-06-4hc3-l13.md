---
layout: post
title:  "4HC3 - Lecture 13"
date:   2020-10-06 11:30:00 -0400
categories: 4HC3
---

Usability Testing
===

Usability Testing
- A technique to evaluate the usability of an interface by testing it on users
    - **Important**: Users actually *use* the interface during a usability test
    - Users typically asked to carry out certain tasks
    - Testers will observe the users using the UI, listening and taking notes
- Usability testing is a form of **user research**
    - Another way to learn user's needs, behaviors, motivations
    - A lot more abstract then "success", "fail", etc.
- Usability testing does not correspond 1-1 with verification/testing in development processes like waterfall/agile
    - Will look at these processes later, ignore for now
    - Usability testing is also about learning about users and how they interact with the UI
- Why conduct usability testing?
    - Identify usability issues
    - Learn if participants successfully complete tasks and "how well" they can complete them
    - Find out how participants think/feel about the UI
        - Subjective satisfaction
- Many ways to conduct usability tests
    - Formal usability testing labs not required
    - Many variations on how to conduct usability testing
    - Can also take place at different stages of development
    - Mainly, asking the user to perform a task while observing how they react is usability testing
    - Good usability tests have a...
        - **Test plan**, documenting all details for how testing will occur
        - **Recruited participants** to take place in the test
        - Findings will be **analyzed and reported**

Types of Usability Tests
- Sketch/Wireframes/Mockup (paper test)
    - User asked to interact with sketches and non-interactive early-stage prototypes
    - Tester switches paper manually to simulate response of user actions
    - Users shown to give better, more open feedback through this!
- Discount Usability Testing
    - More focus on qualitative observations, using earlier stage prototypes and the think-aloud method
    - Test with only ~5 participants
        - Papers written that ~80% issues will be found with only 5 users, diminishing returns above that
        - More people will commonly go over the same issues, requiring more filtering and sorting
        - Can also avoid this though by using 5 people and testing them in multiple iterations
        - Bit of a controversy over all this, but decently accepted in practice
            - Can use more users in different iterations as well if you really want, doesn't need to ONLY be 5 users every test, can use larger test groups as development goes furthers
    - Qualitative observations take less time to prepare
- Competitive Usability Testing
    - Compare one UI to another, with either one group testing A and the other testing B (between-subjects), or all participants testing both (within-subjects, most common)
- A/B Testing
    - Two groups of users randomly assigned to a control group (no change) or a treatment group (with change), and a dependent measure is tested to see if there is a difference with groups
    - Can then use statistical analysis on results to see how different features are better/worse for the system
    - Essentially a between-subjects competitive usability test
    - Widely used in industry
- Remote Usability Testing
    - Done online instead of in-person
    - Can work synchronously to observe participant in real time
        - Sometimes called moderated/monitored remote usability test
    - Can be done asynchronously with users as well, watching a recorded video
        - Unmoderated/unmonitored remote usability test
    - Less ability to observe user behavior
    - More cost effective than in-person (testing in home environment), opens up testing to a larger population
- Other
    - Field Testing: Testing in the environment it will be used in
    - Universal Usability Testing: Testing with diverse users/hardware/software/networks
    - Can-You-Break-This Testing: Users are challenged to find fatal flaws in the interface
        - Commonly used in video games, testers
    - Lab Testing: Done in a usability lab, with two way mirrors, recording equipment, etc.
    - Guerilla Testing: Done in a public place ith randomly chosen participants

Usability Testing Observation Techniques, Tools, and Metrics
- Note-taking
    - As the user performs tasks with UI, take note to analyze and summarize later
    - Can be formal with categories, checklists, questions, etc., but usually just free form written observations
- NOTE: Usability Metrics
    - **Metrics**: Things we measure during a usability test (time to perform a task (in s), ability to complete a task successfully, error rate, etc)
        - Associated with a number result, typically with a unit
    - **Measures** : How we measure metrics
        - How we get and compare the numbers
        - Multiple ways to measure a metric
    - **Logging**: When our application records metrics (like time) to perform tasks and error rates
        - Can add code to record actions, times, etc.
        - Can be useful for remote usability testing, but can be used anywhere
        - High accuracy, can provide exceptional data   
    - Example:  
    ![img]({{ site.url }}/assets/4hc3/comptbl.png)
- Surveys
    - Can be done before/after the user uses the interface to collect data
        - Can be done anonymously, helps for honesty
        - Inexpensive, lots of tools to do this
    - Pre-testing survey focuses to collect demographic data and user characteristics
    - Post-testing surveys are used to collect data about how users think/feel about the UI
    - Can use statistical analysis on survey data, can provide metrics for subjective satisfaction, trustability, etc.
    - Can you a Likert Scale (Strongly Disagree to Strongly Agree, with steps between), to get a metric for more abstract things
        - Can also be done with a Semantic Differential (only end points, middles not labelled)
    - Can ask critical questions about specific aspects of the UI we're concerned about
    - Can also use more free form questions, allowing the user to provide a paragraph of feedback
    - Can design questions for the target user (children, seniors, etc.)
    - Can look at the **System Usability Scale (SUS)** to compute a score of the usability of the UI
        - All Likert Scale questions, score calculated based on average answers
- Interviews
    - Can also be done before usability testing, although always at the end
        - More expensive in time than surveys
    - Can be structured or free form, but usually best to be a mixture of both
    - Conducting Interviews
        - Decide on goals for the interview in advance
        - Explain the purpose of the interview in advance
        - Make then feel comfortable (don't rush, actively listen, be authentic, start with easier questions)
        - Prepare questions in advance
            - Don't have any "leading questions", or questions with bias, essentially avoid anything that may sway their answer
            - Write questions to promote dialog rather than short answers, difference between interview vs survey
            - Anticipate responses and prepare follow-up questions
- Think-Alouds
    - **Concurrent Think Aloud (CTA)** is when the tester asks the participant to think aloud *while* using the interface
        - Less accurate usability metrics like performance time, but goal is to understand stream of thought
    - **Retrospective Think Aloud (RTA)** is when the participant retraces their thoughts *after* they have used the interface
        - Less reliable for understanding thoughts but doesn't interfere with usability metrics
        - Increases total test time
        - Can also use a video to ask what they were thinking at time x
NOTE: The following was done in the next lecture
- Probing
    - **Concurrent Probing** is when the tester asks the participant probing questions about their thoughts as they use the interface
        - eg. Participant becomes confused/excited, tester asks why
        - Issue is it interferes with testing itself
    - **Retrospective Probing** is when tester asks probing questions about their thoughts *after* using the interface
        - Doesn't interfere with testing, but has reliability issues
        - Can be done as a part of a post-test interview
- Other Techniques
    - **Eye-tracking** to determine where users look in an interface
        - Can generate heat maps
    - **First-click testing**, asking the user where they would first click for starting a task
    - **5-Second Testing**, gives users a question, and then shows them the app for 5 seconds to answer it
        - Check if the user can quickly identify something
