---
layout: post
title:  "4E03 - Lecture 29"
date:   2020-11-23 16:30:00 -0400
categories: 4E03
---

Scheduling Continued
===

Continuing off of M/G/1 variance talk...

Priority Queue
- Single server
- Two types of jobs:
    1. $\lambda_1 = 0.063, S_1 ~ Exp(1)$  
    2. $\lambda_1 = 0.007, S_2 ~ Exp(0.01)$
- If we serve FCFS: $\lambda = 0.070$ (poisson process)
- M/M/1 is not valid due to different processing times, use M/G/1:  
$$\frac{1}{\mu} = E[S] = (\frac{0.063}{0.07})E[S_1] + (\frac{0.007}{0.07})E[S_2] = 10.9$$  
$$E[S^2] = (\frac{0.063}{0.07})E[S_1^2] + (\frac{0.007}{0.07}))_E[S_2^2] = 1000.9$$
- M/G/1 Formula gives us $E[T] = 158.7$, where $\rho = \lambda / \mu$
    - From this, we can also get  
    $$E[T_Q] = 158.7 - (1/\mu)$$  
    $$=147.8$$
    - Small jobs are spending most of their time in the queue, and barely any time being processed
    - How can we fix this issue?
- Give **(preemptive) priority** to small jobs!
- Load due to small jobs is given as $\lambda_1 / \mu_1 = 0.063$
- Load due to large jobs: $\lambda_2 / \mu_2 = 0.700$
    - Small jobs often but only take ~6% of system load, while large jobs take 70%
    - Giving small jobs priority may not affect large jobs that much since they have minimal resource usage
    - If most of the load was from small jobs, this would not help much
- For small jobs, we can use a M/M/1 queue equation to calculate the expected time:  
$$E[T] = \frac{1}{\mu_1 - \lambda_1} = 1.07$$  
- For large jobs, using a CTMC simulation:  
$$E[T] \approx 390, E[T_Q]=290$$
- This makes a much better setup for small jobs, but makes larger jobs take more time in queue

SRPT
- Suppose that processing times known upon arrival (this is often a reasonable assumption)
- Give priority to job with **Shortest Remaining Processing Time (SRPT)**
- Optimal in a strong sense- minimizes the number of jobs in the system at every point in time (for any realization of the processing times)
- If it minimizes the number of jobs in the system at every point in time, also minimizes the expected number of jobs in the system, so minimizes the mean response time
- Main issue is that small jobs get blocked commonly by any smaller jobs
    - How can we account for fairness
    - This is a current area of research