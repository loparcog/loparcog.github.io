---
layout: post
title:  "4E03 - Lecture 5"
date:   2020-09-17 16:30:00 -0400
categories: 4E03
---

Scholastic Models
===

Recall
- Capture how a system evolves using dependent random variables, described by some dynamics

Intro Example
- Consider the following (simplified) scenario
    - Three web pages linked to each other, A, B and C
    - Page A links to B, C
    - Page B links to C
    - Page C links to A, B
    - When a user leaves A, 1/3 of the time a link to B is selected, otherwise a link to C is selected
    - B always links to C
    - C links to A and B with equal probability
    - Q: What proportion of visits are made to each page?  
    - This is a discrete-time system
        - The nth "time point" corresponds to the nth page visited
        - Natural for some time settings: a continuous-time framework may be more suitable for others

**Discrete-Time Markov Chains**
- A DTMC is a stochastic process $(X_n, n=0,1,2,...)$ where $X_n$ denotes the state at (discrete) time step n and such that  
$\forall n \geq 0, \forall i, j$ and $\forall i_0, ... , i_{n-1}$  
![img]({{ site.url }}/assets/4e03/dtmc.png)
    - "Last equality" is a property known as *stationary*: Statistics of process independent of time, $P_{ij}$ is independent of the time step and of history
    - "Chain" refers to the state space being discrete
- **Markovian property**: the conditional distribution of any future state $X_{n+1}$, given past states i=0, 1, ..., n - 1, and the present state n, is independent of past states and depends only on the present state $X_n$
- **Transition probability matrix, P**: Associated with any DTMC is a matrix, P, whose ij entry, $P_{ij}$, represents the probability of moving to state j on the next transition, given the current state is i
    - Row of P sum to one - the system must be in some state at each step
    - $P_{ii} \gt 0$ is possible
- Back to the intro example, if the states are taken as A, B, C in that order, then:  
![img]({{ site.url }}/assets/4e03/dtmcex.png)
- Umbrella Problem
    - Absent-minded professor has two umbrellas, used for making trips from home to work and vice versa
    - If it rains and an umbrella is at the current location, an umbrella is taken
    - If it's not raining, no umbrella taken
    - It rains with probability *p* when each trip is made, independent of prior trips
    - Eventual goal: determine the fraction of trips during which the professor gets wet
- Solution written on board
    - $P(X_{n+1} = j \| X_n = i_n, ..., X_0 = i_0)$  
    $ = P(X_{n+1} = j \| X_n = i_n)$  
    Need to choose an X such that this property holds.. but what to chose?
        - Want to look for some variable to keep track of that would affect our new state
        - Could try to use the # of umbrellas, but is tracking the location necessary?
            - No, just know how much at the current location
    - Let $X_n$ = # of umbrellas at the current location (current location being the location the professor is at at time step n)
    - Going to model this with a state space, with states 0, 1, and 2
        - If I am at state 0, I can only go to 2, since the next location must have both umbrellas
        - If I am at state 1, I can either take that umbrella and go to state 2, or leave the umbrella and stay in state 1
        - If I am at state 2, I can either take the umbrella with me and go to 1, or leave it and go to 0
        - All of these branches can be given probabilities given if it rains (*p*) they take an umbrella, and if it doesn't rain (1-*p*) they leave the umbrella
    - Display and matrix shown here:  
    ![img]({{ site.url }}/assets/4e03/umbex.png)
        - One way to check your chain is valid is if your rows each add up to 1
    - Note, choosing the # of umbrellas at your current location is not a unique choice. Another option could be an ordered pair (*x*, *y*), where *x* is the number of umbrellas at home, and *y* is the location of the professor
        - Multiple ways to tackle this, just need to make sure that it's valid. This one is less efficient since there's now 6 states
- So we can put things into Markov chains, how does this help us?
    - Will be displayed below
- n-step Transition Probabilities
    - Let $P^n = P * P * ... * P$, ie. *n* copies of *P* multiplied together
    - $P^n_{ij}$ = (i, j) entry of $P^n$
- 2-step Transition Probabilities
    - Let's look at a 3 state DTMC (states 0, 1, 2)
    - Probability of going from state 0 to 1 in 2 steps is (0>0>1, 0>1>1, 0>2>1)  
    $P_{00}P_{01} + P_{01}P_{11} + P_{02}P_{21}$  
    - So, the required probability is $P_{01}^2$, the (0, 1) entry of $P^2$, in general,  
    $P_{ij}^2 = \sum_{k=0}^{M-1} P_{ik} P_{kj}$    
    so the 2-step probabilities are given by the entries in $P^2$
- In general, we know that the (n-1)-step transition probabilities are given by $P_{ik}^{n-1}$, then by the exhaustive enumeration of all possibilities:  
$P_{ij}^n = \sum_{k=0}^{M-1} P_{ik}^{n-1} P_{kj}$    
This allows an "inductive argument" that the n-step transition probability of going from state i to state j is given by the (i, j) entry of $P^n$
- Now we can try returning to the first problem, also looking at the probability of going to different steps, $p^2$
    - As the value of n starts to go up, the rows start to become the same as one another. This says that the probability of being in state *j* becomes independent of starting state *i*
- Limiting Probabilities
    - Let  
    $\pi_j = \lim_{n \rightarrow \inf} P^n_{ij}$
    - The values $\pi_j$ represents the limiting probability that the DTMC is in state *j*. For an *M*-state DTMC, with states 0, 1, ..., *M*-1  
    $\pi = [\pi_0, \pi_1, ..., \pi_{M-1}]$, where $\sum_{i=0}^{M-1} \pi_i = 1$
    - Not obvious that limit always exists (in fact, sometimes does not)
    - No obvious limiting properties form a distribution