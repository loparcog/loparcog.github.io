---
layout: post
title:  "4J03 - Lecture 11"
date:   2021-04-01 10:00:00 -0500
categories: 4J03
---

Congestion Control
===

Flow Control vs Congestion Control
- **Flow control:** Preventing senders from overrunning the buffer capacity of the receivers
- **Congestion control:** Preventing too much data from being injected into the network, causing switches or links to become overloaded

Congestion Control Basics
- **Problem**
    - Demand for network resources can grow beyond the resources available
    - Contention at routers causes packet loss
    - Want to provide "fair" amount to each user
- **Goal**
    - Achieve effective and fair allocation of resources among a collection of competing users
    - Learning when to say no and to whom
- Overview:
    ![img]({{ site.url }}/assets/4j03/cco.PNG) 
- Basic Design Choices
    - Prevention or Cure?
        - Pre-allocate resources to avoid congestion
        - Send data and control congestion if and when it occurs
    - Implementation points
        - Hosts at the edge of the network
            - Transport protocol
        - Routers inside the network
            - Queueing disciplines
- Router role
    - Controls forwarding and dropping policies
    - Can send feedback to source on if congestion is occurring and if packets are being dropped
- Host role
    - Monitor network conditions if congestion occurs
    - Adjust sending accordingly
- Routing vs congestion
    - Effective adaptive routing schemes can sometimes alleviate congestion
    - **...but not always**
- Feedback in CC: Telling hosts whether the network is congested or not
    - Implicit feedback: Routers drop packets, sender send timeouts as an indication of congestion
    - Explicit feedback: Sender sets specific bit flag in the header, receiver sets bit flag in ACK to let host know about congestion
    - Which is better
        - Prefer **implicit**, small overhead
        - Explicit feedback requires busy routers, so performance will suffer

Per-Flow Congestion Feedback
- Question
    - Why is per-flow congestion feedback from routers rarely used in practice?
- Problem
    - Too many sources to track, and add complexity to routers
        - Millions of flows may fan in to one router
        - Certainly can't track state for all sources
        - Can't send feedback to all of them
    - Can't force the sources (hosts) to use feedback
- Solution
    - Use implicit feedback
    - Do not track flow status
    - Use stochastic methods to fairly select packets to drop between flows

Evaluation
- CC problem is actually a resource allocation problem
- Two metrics used to measure the resource allocation solutions:
    1. Fairness
    2. Efficiency (Power)
        - Ratio of throughput to delay
        - Function of load on network
- Example graph:  
    ![img]({{ site.url }}/assets/4j03/cce.PNG) 
- Ratio of throughput to delay:  
    ![img]({{ site.url }}/assets/4j03/ccr.PNG) 
- What's fair?  
    ![img]({{ site.url }}/assets/4j03/fair.PNG) 
    - **Globally Fair:** A = Capacity/4, B = C = D = 3 * Capacity/4
        - Overall bandwidth equal for all flows
    - **Locally Fair:** A = B = C = D = Capacity/2
        - Bandwidth of each link is equally shared
        - This is the so-called "max-min fair" rate allocation, where the minimum rate is maximized

Queueing Disciplines
- **Goal:** Decide how packets are buffered while waiting to be transmitted
- Allocates...
    - Bandwidth: Which packets get transmitted
    - Buffer Space: Which packets get discarded
- Affects Packet Latency: When packets get transmitted
- **FIFO** (First in First out)  
    ![img]({{ site.url }}/assets/4j03/fifo.PNG) 
    - Does not discriminate between traffic sources
    - Fairness for latency
    - Utilizes **tail drop**, dropping any arriving packet at a full buffer
- **Priority Queueing**:  
    ![img]({{ site.url }}/assets/4j03/pq.PNG) 
    - Several queues with different priorities
    - Higher priority queue is always served if not empty
    - Lower served whenever ones above them are empty
- **Fair Queueing (FQ)**
    - Explicitly segregates traffic based on flows
    - Ensures no flow captures more than its share of the capacity
    - Fairness for bandwidth
    - Each flow guaranteed 1/n of capacity, where n is the number of flows

Fair Queueing with Variable Packet Length
- How should we implement FQ if packets are not all the same length?
    - Bit-by-bit round-robin?
        - Not feasible to implement, must use packet scheduling
        - Solution: **Approximate**
- Idea
    - Let $S_i$ = amount of service flow *i* has received so far
    - Always serve a flow with minimum value of $S_i$
        - Can also use minimum ($S_i$ + next packet length)
    - Upon serving a packet of length *P* from flow *i*, update $S_i = S_i + P$

Extension: Weighted Fair Queueing
- Extend fair queueing
    - Notion of importance foe each flow
- Suppose flow *i* has weight $w_i$
    - Ex: $w_i$ could be the fraction of total service that flow *i* is targeted for
- Need only change basic update to $S_i = S_i + P/w_i$

TCP Congestion Control
===

TCP Congestion Control
- Idea
    - Router Solution (assume best-effort network): FIFO or FQ
    - Host Solution: Each source determines network condition from implicit feedback
- Host solutions info
    - Host has very little information
        - Assumes best-effort network
        - Acts independently of other hosts
    - Host infers congestion
        - From feedback (eg. dropped packet timeouts, duplicate ACKs)
        - Loss on wired lines rarely due to transmission error
    - Host acts
        - Reduce transmission rate below congestion threshold
        - Continuously monitor network for signs of congestion
- Basic idea
    - Remember **advertised window**
    - Add notion of **congestion window**
    - `MaxWindowSize = min(AdvertisedWindow, CongestionWindow)`
    - Changes in **congestion window** size
        - Slowly increase to absorb new available bandwidth
        - Quickly decrease to eliminate congestion
- Specific strategy
    - Self-clocking
        -Send data only when outstanding data ACK'd
    - Increase
        - Additive increase by increasing the window size linearly
    - Decrease
        - Multiplicative decrease by cutting window in half when timeout occurs (set window = window/2)
    - Known as **additive increase, multiplicative decrease (AIMD)**
        - Always either increasing or decreasing, never stagnant

Additive Increase/Multiplicative Decrease
- New TCP state variable
    - `CongestionWindow`: Similar to `AdvertisedWindow` for flow control
    - Limits how much data source can have in transit
        - `MaxWin = min(CongestionWindow, Advertised Window)`
        - `EffWin = MaxWin - (LastByteSent - LastByteAcked)`
        - TCP can send no faster than the slowest component, network, or destination
- Idea
    - Increase `CongestionWindow` when congestion goes down
    - Decrease `CongestionWindow` when congestion goes up
- Algorithm
    - Increase `CongestionWindow` by one packet per RTT (linear increase)
    - Divide `CongestionWindow` by two whenever a timeout occurs (multiplicative decrease)  
        ![img]({{ site.url }}/assets/4j03/aimd1.PNG) 
    - Leaves a "sawtooth" pattern:
        ![img]({{ site.url }}/assets/4j03/aimd2.PNG) 
- Why is AIMD fair?
    - Two competing sessions
    - Additive increase gives slope of 1, as throughput increases
    - Multiplicative decrease decreased throughput proportionately  
        ![img]({{ site.url }}/assets/4j03/aimdf.PNG) 

TCP Start Up Behaviour
- How should TCP start sending data?
    - AIMD is good for channels operating at capacity
    - AIMD can take a long time to ramp up to full capacity from nothing
    - Use **slow start** to increase window *rapidly* from a cold start

Slow Start
- Objective
    - Determine initial available capacity
- Idea
    - Begin with `CongestionWindow = 1 packet`
    - Double `CW` each RTT
        - Increment by 1 packet for each ACK
    - Continue increasing until loss
- Result
    - Exponential growth
    - Slower than all at once
- Used
    - When first starting connection
    - When connection times out  
        ![img]({{ site.url }}/assets/4j03/slows.PNG) 
- TCP Congestion Control w/ SS: To ramp up congestion window quickly
    - Maintain threshold window size:
        - Set to 1/2 of current window on timeout
        - Initially set to maximum window size
    - Use multiplicative increase
        - When congestion window smaller than threshold, double window size per RTT
        - When bigger, switch to additive increase
        - In practice, increase congestion window by one MSS for each ACK of new data
- Example
    - Initial values
        - `CongestionThreshold = 8`
        - `CongestionWindow = 1`
    - Loss after transmission 7
        - Currently, `CongestionWindow = 12`
        - Set `CongestionThreshold = CongestionWindow/2`
        - Set `CongestionWindow = 1`
    - Graph:  
        ![img]({{ site.url }}/assets/4j03/slowsex.PNG) 

Fast Retransmit
- Problem
    - Coarse-grain TCP timeouts lead to idle period
- Solution
    - **Fast Retransmit**: Use three duplicate ACKs to trigger retransmission  
        ![img]({{ site.url }}/assets/4j03/fr.PNG) 

Fast Recovery
- When fast retransmission occurs, skip slow start
- Congestion window becomes 1/2 previous, along with threshold
- Start additive increase immediately  
- Example congestion window trace:  
        ![img]({{ site.url }}/assets/4j03/exw.PNG) 

Congestion Avoidance
- Control vs avoidance
    - **Control:** Minimize impact of congestion when it occurs
    - **Avoidance:** Avoid producing congestion
- In terms of operating point limits:  
    ![img]({{ site.url }}/assets/4j03/cpwr.PNG) 
- TCP's strategy
    - Control congestion once it happens
    - Repeatedly increase load in an effort to find the point at which congestion occurs, then back off
- Alternative strategy
    - Predict when congestion is about to happen and reduce the rate at which hosts send data just before packets start being discarded

Router-Based Congestion Avoidance
- **Random Early Detection (RED)** gateways
    - Developed for use with TCP
    - Basic idea
        - Implicit rather than explicit notification
        - When a router is "almost" congested, drop a random packet
    - Responsibility is again shared
        - Router identifies, host acts
        - Relies on TCP's response to dropped packets

Random Early Detection (RED)
- Routers
    - Compute average queue length (exponential moving average)
        - `AvgLen = (1 - Weight) * AvgLen + Weight * SampleLen`
        - `0 < Weight < 1` (usually 0.002)
        - `SampleLen` is queue length at packet arrival time
- Dropping Policy
    - If `AvgLen <= MinThreshold`, enqueue packet
    - If `MinThreshold < AvgLen < MaxThreshold`, calculate *P* and drop arriving packet with probability *P*
    - If `MaxThreshold <= Avglen`, drop arriving packert
- Dropping Probability
     - Computing *P*
        - `Count` is the number of packets that have arrived since the last packet drop
        - *P* is a function of `AvgLen` and `Count`
    - Formula and graph:  
        ![img]({{ site.url }}/assets/4j03/p.PNG) 

Source-Based Congestion Avoidance
- Idea
    - Source watches for some sign that some router's queue is building up and congestion will happen soon
- Examples
    - RTT is growing
    - Throughput decreasing
- Observe RTT
    - If current RTT is greater than average of minRTT and maxRTT, decrease congestion window by 1/8
- Observe throughput
    - Compare measured throughput with expected throughput, where  
    `ExpectedThroughput = CongestionWindow / MinMeasuredRTT`
    - Change the `CongestionWindow` based on the difference between the measured throughput and the expected throughput
    - Used in TCP Vegas