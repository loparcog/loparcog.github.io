---
layout: post
title:  "4E03 - Lecture 8"
date:   2020-09-24 16:30:00 -0400
categories: 4E03
---

Further DTMC & Operational Analysis
===

Caching Example
- DTMC's used commonly in caching schemes
- We want to compare strategies for virtual memory paging in an OS
- We will model the system as a *ranked* set of pages
- Supposed there are 8 pages, $P_i$, currently ranked (highest to lowest):  
3, 7, 2, 6, 5, 1, 8, 4
- Next request is for page $P_5$
- New ranking under "least recently used" (LRU)? 
    - 5, 3, 7, 2, 6, 1, 8, 4
    - Same ranking but now 5 is on top
- New ranking under "move-ahead" (move up one in the ranking)?
    - 3, 7, 2, 5, 6, 1, 8, 4
    - 5 will move up one more rank, swapping with 6
- For example, suppose the first **three** pages are in memory
    - If trying to access a page not in memory, a cache miss will occur
- System State
    - If *N* is the number of pages, state is permutation of (1, ... , *N*)
    - Size of state space is *N*!
    - Linux system: page size is 4kB, memory size is 1GB, swap disk size is 1GB, so state space has size 500 000!
- Request Model
    - Requests are random
    - Requests follow an *independent and identically distributed* (i.i.d.) sequence with:  
    $P(R_n = P_i) = p_i$
    - Supposed we want to consider performance when there is a "more frequent page" $P_A$
    - Assume that:  
    $a = P(R_n = P_A)$  
    $b = P(R_n = P_i), P_i \ne P_A
        - *a* and *b* satisfy $a \gt b$ and $a + (N-1)b = 1$
    - Note, this allows that *a* is (much) smaller than $(N-1)b$
    - Can we reduce the state space?
- LRU Transition Matrix:  
AAA (finish)

**Operational Analysis**
- Going to work in the context of a *Queueing System*
    - A simple queue consists of a buffer/queue where arriving jobs wait to be served by a server, after completion they depart
    - Must describe
        1. Arrivals: The time between arrivals is given by a probability distribution
        2. Queue: Size, infinite or finite
        3. How server operates: Number of servers, order of service (FCFS, LCFS, etc, like FIFO), processing times (the probability distribution that determines them)
- Performance Indicators/Metrics
    1. Response time: Time from arrival to departure
    2. Throughput: Number of jobs served per unit time
- Also interested in queueing networks
    - Queues connected together, running together
- Analysis directions
    - We're faced with two possibilities when doing analysis:
    1. Exact Analysis: Try to formulate equations that yield the desired performance metric, then solve
    2. Simulation: By generating realizations/samples from the underlying distributions, we can follow the logic of the system to estimate the performance measure(s) of interest. 
        - For example, generate a (large) number of "real" response times, compute average
- Operational laws
    - First cut at analytical model *operating in continuous time* (DTMC is discrete). Supposed we have the following data:
        - $A_i(t)$: Number of arrivals to device/node *i* at time *t*
        - $C_i(t)$: Number of completions (departures) from note *i* at time *t*
        - $B_i(t)$: Busy time of node *i* at time *t*
- Some simple calculations
    - From the data, we can quickly derive the following quantities:
        - Arrival rate at node *i*: $\lambda_i(t) = A_i(t)/t$
        - Throughput of node *i*: $X_i(t) = C_i(t)/t$
        - Utilization of node *i*: $\rho_i(t) = B_i(t)/t$
        - Average processing time at node *i*: $S_i(t) = B_i(t)/C_i(t)$
AAA (finish up to Utilization Law)
