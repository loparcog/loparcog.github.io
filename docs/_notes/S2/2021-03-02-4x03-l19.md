---
layout: post
title:  "4X03 - Lecture 19"
date:   2021-03-02 11:30:00 -0500
categories: 4X03
---

NOTE: Lecture 18 was the midterm

Linear Least Squares
===

Ex: Linear Least Squares Fit
- Assume a programs runs in $\alpha n^{\beta}$, where $\alpha$ and $\beta$ are real constants we don't know
    - How do we determine them?
- Run the program with sizes $n_1, n_2, ..., n_m$ and measure the corresponding CPU times $t_1, t_2, ..., t_m$, where $m \gt 2$
- Write $\alpha n_i^{\beta} = t_i, i = 1, ..., m$
- Then:  
    $$\ln \alpha + \beta \ln n_i = \ln t_i, i = 1, ..., m$$
- Let $x = \ln \alpha$, then:  
    $$1 * x + \ln n_i * \beta = \ln t_i, i = 1, ..., m$$
- We can then get a system of equations for each value of *i* from 1 to *m*
- This gives us the following matrix:  
    $$Ay = \begin{bmatrix}
    1 & \ln n_1 \\
    1 & \ln n_2 \\
    \vdots & \vdots \\
    1 & \ln n_m \\
    \end{bmatrix} \begin{bmatrix}
    x \\ \beta \\
    \end{bmatrix} = \begin{bmatrix}
    \ln t_1 \\ \ln t_2 \\
    \vdots \\ \ln t_m \\
    \end{bmatrix} = b$$
- Finally, solve in Matlab as `y = A\b`

Solving Overdetermined Systems
- $A \in \mathbb{R}^{m*n}, b \in \mathbb{R}^m$, where $m \gt n$
- $Ax = b$ is an **overdetermined system** since there are more equations than variables
- We want to find *x* that minimizes $\vert \vert b - Ax \vert \vert_2$
- We can get the equation $r = b - Ax$, which solves as:  
    $$\vert \vert r \vert \vert_2^2 = \sum_{i=1}^m r^2_i = \sum_{i=1}^m \left( b_i - \sum_{j=1}^n a_{ij} x_j \right)^2$$
- Then, let:  
    $$\phi(x) = \frac12 \vert \vert r \vert \vert_2^2$$
- We want to find the minimum of $\phi(x)$, with the necessary condition of:  
    $$\frac{\delta \phi}{\delta x_k} = 0, k = 1, ..., n$$
- Gives us a final system to solve of:  
    $$\sum_{i=1}^m a_{ik}b_i, k=1, ..., n$$

Normal Equations
- The above system is the same as:  
    $$A^T Ax = A^T b$$
- These are called **normal equations**
- If *A* has a full-column rank (all columns are linearly independent), then:  
    $$\min_x \vert \vert b - Ax \vert \vert_2$$  
    has a unique solution, which is the solution to $A^T b$:  
    $$x = (A^T A)^{-1} A^T b = A^{\dagger}b$$
- $A^{\dagger} = (A^T A)^{-1} A^T$ is the *pseudo inverse* of *A*