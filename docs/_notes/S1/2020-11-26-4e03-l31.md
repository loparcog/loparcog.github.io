---
layout: post
title:  "4E03 - Lecture 31"
date:   2020-11-26 16:30:00 -0400
categories: 4E03
---

Routing and Load Balancing
===

Routing/Load Balancing
- Fundamental problem in large-scale systems
- Load balancer assigns incoming arrivals to backend servers

Simplest System
- For insight purposes, assume that we have arrivals that follow a Poisson process with rate $\lambda$, $N$ servers in parallel, and processing times at each server are exponentially distributed with rate $\mu$
- Routing decisions must be made upon arrival of a job
- Random Routing
    - We have already discussed that the best choice of routing probabilities is $1/N$
    - Result is $N$ M/M/1 queues
    - Available in many (all) commercial load balancers
    - Can we reduce the variance of interarrival times? 
    - Why is random routing potentially problematic?
        - It doesn't consider the number of jobs, looks at "long term" load
- Round Robin
    - Assign incoming jobs to the servers in the order 1, 2, ..., *N*, 1, 2, ..., *N*, 1, 2, ...
    - Arrival rate remains unchanged $(\lambda/N)$, but can show that interarrival time variance is minimized
    - Also available in many (all) commercial load balancers
    - Weighted round robin is typically available (can assign more load to some servers)
    - Arrivals are not a Poisson process, so this is not an M/M/1 queue, but a G/M/1 queue
        - Outside of course, but G is for general instead of M for markovian 
- Random Routing/Round Robin
    - Both routing policies balance load in a "long term" sense, they get the rates correct
    - Have the desirable property that they do not need to know any information about backend servers
    - What if information is available, can we balance short term load?
- Join the Shortest Queue (JSQ)
    - Assume that the load balancer knows the current queue length at all servers
    - Send an arrival to the shortest queue (breaks ties randomly)
    - Can show: as the system load goes to one ($\lambda$ approaches $N \mu$), the mean response time for JSQ approaches that of an M/M/N system
    - From our earlier work, know that this is the best possible
    - Problems can arise with delay between reporting queue sizes and acting on reported info
    - Drawbacks
        - Huge amount of communication overhead
        - One possible remedy: "the power of two choices", choose two queues at random, join the shortest of the two
        - Communication latencies, resulting in load balancer having outdated information
        - Load balancers do implement this (least connections)
- Another Possibility
    - What if servers signal load balancer when they're idle?
    - Turns problem on its head, rather than load balancer determining state of servers, servers are proactive
    - An arrival is sent to an idle server, otherwise use random routing
    - From our work on multiserver systems, we know the probability of an idle server is high
    - Reasonably approximates to an M/M/*N* system (which is optimal)