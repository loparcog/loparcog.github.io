---
layout: post
title:  "4HC3 - Lecture 25"
date:   2020-11-12 11:30:00 -0400
categories: 4HC3
---

Simulations, Game Loops, and Game Engines
===

Simulations
- **Computer simulations** use step-by-step methods to explore behavior of a mathematical model
    - Often the model is some sort of physical system
- **Interactive computer simulations** involve human interaction (sometimes called "human in the loop")
    - Flight simulators, surgery simulators, etc.
- Simulations very closely related to video games
- Interactive simulations are often used in education, healthcare, machinery training
    - Areas where cost of mistakes are very high, or training is expensive
- **Virtual simulations** are the recreation of reality depicted on a computer screen that injects humans in a central role by exercising motor control skills, decision skills, or communication skills
    - Distinct from VR headsets
    - Can be point-and-click, but still "simulate reality"
    - In attempt to recreate reality, virtual sims may use unconventional HCI inputs/outputs
    - Display outputs include head mounted displays (VR headset), wrap-around displays (cockpit views), CAVE displays (visualization projected onto 4 surrounding surfaces)
    - I/O can include things like **haptic technologies** (touch)
        - Apply forces, vibrations, or motions to the user
        - Useful for simulating situations such as the usage of the surgical tools
        - The "rumble" feature in video game controllers is an example of haptic technologies
    - Other I/O includes omnidirectional treadmills (walk/run in any direction, capture motion), motion capture suits (record body movement), and high fidelity controls/instruments (eg. realistic airplane cockpit controls)

Designing Simulations
- Everything we've talked about with regular interfaces applies to simulation interfaces (design heuristics, principles and theories, etc.)
- Soecialized design guidelines have also been designed for virtual simulations and VR
    - Far less research in this area though, less user application and highly specialized
- With virtual simulations attempting to recreate a real situation, an additional UI goal is to meaningfully recreate the situation for the user
    - As a result, many guidelines are focussed on this goal either through an increased sense of immersion, or increase recreation of reality
- Heuristics for VR
    - Synchronous body movements (stay in sync with human head/body movements to prevent lag)
    - Phyiscal space constraints (account for real-world physical space VR will be used in)
    - Immersion
    - Minimal "Glitchiness"
    - Minimize switching between actual world and virtual world
    - Cord design (keep tangling and complex cord systems to a minimum)
    - Headset comfort (physical comfort)
    - Mental comfort (avoid nausea, physical illness, etc)
    - More research in lecture slides
- What tools are used to make simulations and video games?
    - Frames are rendered and displayed in quick succession, giving appearance of motion
    - Simulations and video games are generally soft real-time systems
        - 30fps target, games often judged by frame work
        - Lots of work to do for each frame

Game Loops
- While the game is running, this process...
    - Processes inputs
    - Update game state
    - Render frame
- Processing inputs
    - Inputs are things like button presses, mouse movements, etc
    - Detecting these varies from technology to technology, but same concept as event-driven programming
    - Events can be recognized asynchronously, and processed at the next game loop
- Update game state
    - Position of any object, including velocities, changes in direction, collision, etc
    - Would also include any AI processing
- Rendering frames
    - State of the game is drawn to the screen
    - Typically a rendering API handles this
        - 2D would include squares/circles/etc., whereas 3D rendering would include polygons, textures/effects, etc
    - Rendering is an expensive operation, especially for complex 3D games
        - Millions of polygons rendered per frame, with effects applied
        - Many fascinating optimizations in place now though, improving rendering capabilities
- Game state
    - Updating the game state can get very complex
        - Physics computations, collision detection, AI decisions, etc.
    - Collision detection
        - Can do simple detection by checking if the boundaries have intersected or will intersect
            - Called **bounding box collision detection**
        - What about very fast objects? Would bypass bounding box collision sometimes
            - Would need to move to **continuous collision detection** (discrete checking frame by frame, continuous checking for intersection of paths, etc)
        - Further complications when objects are obtuse shapes

Game Engines
- Many problems related to physics/rendering are common across video games
    - Up until mid 90s, video games would *individually* solve these problems
- Now, move towards game engines, general solutions towards common game problems that could be built on top of
    - Became cost effective to license game engines rather than work from scratch
- Two very popular ones:
    - Unreal - popular with AAA titles
    - Unity - popular with indie game developers
- Game engines have made game dev economically viable for smaller independent studios
    - Also used to create virtual simulations and VR software