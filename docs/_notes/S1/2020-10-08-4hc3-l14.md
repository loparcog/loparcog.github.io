---
layout: post
title:  "4HC3 - Lecture 14"
date:   2020-10-08 11:30:00 -0400
categories: 4HC3
---

Test Plans
===

Usability Test Plans
- Document all aspects on *how* the test will occur, including:
    - Scope
        - What application is being tested?
        - What feature(s) of the application are being tested?
        - When is the testing occurring (development stage)? What version of the project/interface?
    - Purpose
        - What are you concerned with? What questions do you want to answer through the usability test?
        - What are your goals in conducting the test? (Can be very general/specific)
            - General ex: Can users easily learn how to use the application?
            - Specific ex: Can the users find the shopping cart button?
        - Goal Info
            - You only have so much time with each user, don't overwhelm with many goals
                - How many goals can you realistically achieve?
            - Goals should drive decisions about the design of the rest of the test plan
            - Goals should be carefully thought out, tied to goals for your applications and concerns about its design
    - Schedule/location
        - When/where will the test take place?
        - Remotely or in person?
        - How many sessions? Be specific!
    - Format
        - Moderated or unmoderated? (Synchronous or asynchronous)
            - Synchronous are moderated, tester guides the user verbally through task and directly interviewing and asking follow up questions
            - Async are unmoderated, with the tester giving the participant a script to follow themselves
                - Follow up is still possible through email, call, etc
    - Participants
        - Who are the participants?
        - How were they recruited or how will they be recruited?
        - How well do they match the target demographic(s)?
    - Equipment
        - What equipment used during the test? (hardware and software)
        - What will be recorded, if anything?
        - If it matters, we may want to describe screen resolution, sizes, input devices, etc.
    - Roles
        - Who will conduct the usability tests, what role will they play?
            - Might be one tester and one participant, or a whole team to monitor each participant and take notes, record, etc.
        - A usability specialist might conduct the test, and a notetaker might take primary responsibility for taking notes
    - Sessions
        - What is the order of activities for a test session with a participant? Ex:
            - Pre-study survey
            - Ask participant to perform task X/Y/Z, etc.
            - Post-study survey
            - Post-study interview
        - How long will a session take?
            - 60-90m typical in a large application
            - Tests can be done in 10-20m for smaller application, or tests focused on particular aspects of an application
    - Tasks/Scenarios
        - What tasks will you ask the user to carry out?
            - Comes from task hierarchy, at different depths of the tree
        - Tasks are generally better written in the form of scenarios with specific info, also called "task scenarios"
            - eg. instead of "use the app to buy a book", the task will be "use the app to find and buy the book 1984"
            - Ask for something specific for a more objective test, no wondering on what book to look for/buy
        - **Exploratory tasks** are open-ended, may not have a specific correct answer
            - Better to see how people think/navigate
        - **Specific tasks** are more focused and have a definitive end point
            - More useful, can gather quantitative and qualitative data
    - Observations
        - How will you be making observations? (Notes, recording, etc.)
        - Metrics and instruments
            - Will you be recording any metrics?
            - Will you be conducting any interviews/surveys (instruments)?
    - Metrics
        - What quantitative metrics will you measure?
        - How will you measure them? (what tools used)
        - Will you produce metrics for user feelings and thoughts that don't have straightforward quantifications?
            - How will you measure them?
            - Can be done on the whole test or on a per-task basis
            - Mainly for subjective satisfaction, trustability, other non-objective tools
    - Instruments (surveys/interviews)
        - Surveys
            - Will participants complete a survey?
            - What surveys will participants complete?
            - What questions are on the survey?
                - Are standards like SUS being used?
            - When will participants complete the survey?
        - Interviews
            - Will interviews be conducted? When?
            - Is there a script of preset interview questions?
            - Scripted? Unscripted? Mix?
                - In case of async, log any emails or questions that will be asked later on
    - Participant instruction (in case of async testing)
        - If the usability test is async, the test plan should include instructions for the tester to complete the test, like how to access the application, any pre-test surveys, any recording checks or processes to follow while testing, any post-test surveys or chats
            - No more than a page, keep it not complicated
        - Tester can be expected to carry out instructions
    - NOTE: Lots of these can be called different things, and also can usually be answered in one line or many pages, just sort of headers
        - Lengthy isn't good necessarily, want to make sure you're getting information you need (especially in surveys)
        - Also not all headers *need* to be used in *every* test plan
- Some example usability test plans are given in lecture slides
    - Can use for ideas, would generally want to tailor for your own application, with your own goals in mid
    - Documented formally as well so it could be reproduced
- How to recruit participants?
    - Most important thing is to ensure participants are similar to your target user!
        - If you have multiple groups, recruit participants similar to each group
        - Beyond this, the actual form of recruitment could be whatever works: emails, social media posts, posters, etc.
    - Avoid conflicts of interest
        - Internal staff, people involved in project or personal life may not be honest because they want to see it succeed
    - Discount usability testing suggests 5 participants
    - If we want to produce a statistically significant result, at least 20 participants
        - Though more are often required
        - Tests like this can begin to resemble formal HCI experiments (will be covered later)
        - At this point, ensuring recruitment is "random" is also important
    - Participants can also be screened for
        - Demographic
        - Personality
        - Work experience/background knowledge
    - For niche applications, screening becomes more important
    - Compensating participants ensure they take the test more seriously

Usability Test Report
- Test results may be reported verbally in a meeting, perhaps w/ slides, or might be reported in a formal written report
- Usability test reports should include:
    - Background summary
        - Made up of scope, purpose, and schedule/location
    - Methodology
        - Made up of format, participants, equipment, etc., all other fields of plan
    - Test results
        - Present data collected (survey data, metrics recorded, interview data, note taking observations)
        - Utilize tables, graphs, screen captures, wherever illustrative or helpful to present the data and results
        - Beyond what you intend to measure/observe, was there anything unexpected to report?
            - This could include bugs, issues you may not have been testing for, etc.
    - Analysis of results
        - What was learned? What is evident/likely from the results?
            - We call what was learned as **findings**
        - How does data support the findings?
        - What usability issues were identified?
            - Can sort from low/medium/high/critical
            - Frequency of occurrence may also factor into what section to put it in
        - Can report findings on a per-scenario basis, or aggregate, or both
        - Don't want analysis to be exclusively negative
            - What positives were found? What is working well and should be continued?
            - Good for morale of the dev team
        - Findings should be as *specific as possible*
        - Example of findings table in lecture
    - Recommendations
        - Changes recommended as a result of the findings of the usability test
        - Recommendations should be associated with findings
        - What is the reasoning for the recommendation?
            - Not the same as the findings, reasoning is why you believe the recommendation will *address* the finding
            - eg. We should move the search bar to the top-right because that's where users were shifting their focus to look for it
- Can use these as headings or not, generally this information is needed
    - Sometimes more added, ie. "executive summary"
- Links to example usability test reports in the slides

