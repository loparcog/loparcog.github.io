---
layout: post
title:  "3Y03 - Week 1 Notes"
description: "Notes from W1 slides"
date:   2020-09-09 21:00:00 -0400
categories: 3Y03
---

**Intro to Probability Theory**
- Stats is the science of collecting, analyzing, and inferring from data
- Probability is the mathematics of random events, intimately related to statistics
- An **experiment** is anything that produces data, while a **random experiment** is an experiment that can produce different outcomes with the same process
    - Flipping a coin is a random experiment, outcomes being H or T
- A **sample space**, S, is the set of all outcomes of a random experiment
    - A sample space is **discrete** if it is finite or countably infinite (like the set of all integers/natural numbers). Otherwise, it is **continuous** (like a set of real numbers)
- Given a sample space S, and **event** is a subset *E $\subseteq$ S*
    - With tossing a coin three times, we may be interested in the event consisting of outcomes with two or more heads. This would look like:  
    *E = {HHH, HHT, HTH, THH} $\subseteq$ {HHH, HHT, ...} = S*
- Given some events, we can build new events as follows: Given $E$, $E_1$, and $E_2$ are events from a sample space $S$, then:
    - The **union**,  
    *$E_1 \cup E_2$ := {x $\in$ $S$ : x $\in E_1$ or x $\in E_2$}*  
    the **intersection**  
    *$E_1 \cap E_2$ := {x $\in$ $S$ : x $\in E_1$ and x $\in E_2$}*  
    and the **complement**  
    *$E'$ = {x $\in$ $S$ : x $\notin$ $E$}*  
    are all events as well
- Also note the following:
    - If $E$ $\subseteq$ $S$ is any event, then $E$ $\cup$ $E'$ = $S$ and $E$ $\cap$ $E'$ = $\emptyset$
    - Both $S$ and $\emptyset$ are also events, and $S'$ = $\emptyset$ and vice versa
- Given a sample space $S$, two events $E_1$, $E_2$ $\subseteq$ $S$ are **mutually exclusive** if $E_1 \cap E_2$ = $\emptyset$
    - The intuition is that mutually exclusive events **cannot happen simultaneously**, which, using the coin example with space $S$ = {H, T}, would be the events $E_1$ = {H} and $E_2$ = {T}
- Some useful rules for **manipulating events** algebraically can be found below, using events A, B, C $\subseteq$ S
    - (A')' = A
    - Distributivity:
        - (A $\cup$ B) $\cap$ C = (A $\cap$ C) $\cup$ (B $\cap$ C) 
        - (A $\cap$ B) $\cup$ C = (A $\cup$ C) $\cap$ (B $\cup$ C)
    - DeMorgan's Laws:
        - (A $\cup$ B)' = A' $\cap$ B'
        - (A $\cap$ B)' = A' $\cup$ B'

**Counting Techniques**
- It's often important to determine the size of a finite sample space, which, for example, could be the number of possible outcomes to thew experiment of tossing a coin three times
- Suppose we have r-many experiments, and suppose the ith experiment has n<sub>i</sub>-many possible outcomes. Then, the total number of outcomes for running all the experiments consecutively is:  

$$\prod_{i=1}^{r} n_i = n_1 n_2 ... n_{r-1} n_r$$

- Using this equation on the coin example, given that we're tossing the coin three times and each coin toss has two outcomes, the total number of outcomes is 2<sup>3</sup> = 2 $\cdot$ 2 $\cdot$ 2 = 8
- Can also use this technique to count other phenomena, like how many ways can we arrage (**permutate**) the letters "a", "b", "c"?
    - The permutations are abc, acb, bac, bca, cab, cba (6 permutations). This is done by choosing one of the 3 letters first, then picking one of the 2 leftover, then putting the last one in, giving 3 $\cdot$ 2 $\cdot$ 1 = 6 possibilities
- Given n distinct objects, the number of ways to **permutate** them is:

$$n! = n \cdot (n-1)\cdot(n-2)\cdot...\cdot3\cdot2\cdot1$$

- By similar reasoning, we can make a more general counting technique for permutations. Given a set of n distinct objects, the number of ways to permutate r $\leq$ n of them is:

$$P_{r}^{n} = nPr = n \cdot (n-1) \cdot ... \cdot (n - r + 1) = \frac{n!}{(n-r)!}$$

- An example for this would be all three letter words with no repeated letters, permutating 3 choices from a choice of 26, which would be $P_3^{26} = 26 \cdot 25 \cdot 24$
- What about a permutation where some of the objects aren't unique?
    - For example, the number of ways to permutate the letters in the word BANANA
    - If all the letters were unique, there would be 6! permutations, but there are 3 A's and 2 N's, which would mean some of the 6! permutations would be the same
    - There are 3! ways to permute the A's and 2! ways to permute the N's, and if we were to cancel these out, we would get $\frac{6!}{3!2!} = 60$ many unique permutations of BANANA
- Given $n = n_1 + ... + n_r$ many objects, with $n_i$ identical many objects of type i, the number of unique permutations of the object is:

$$\frac{n!}{n_1!n_2!...n_r!}$$

- Suppose there are 10 people and you want to choose 5 of them to make a team. How many ways are there to do this?
    - This choice is called a **combination**, different than permutations since we don't care about order. Can still use similar math though!
- With permutation, there would be 10 $\cdot$ 9 $\cdot$ 8 $\cdot$ 7 $\cdot$ 6 many ways to choose 5 people, but as we said, order doesn't matter
    - But we also know that given a group of 5 distinct objects, there are 5! permutations, so we should cancel them out
- Therefore, we end up with $\frac{10\cdot9\cdot8\cdot7\cdot6}{5!}$ ways to choose 5 people from a group of 10.
- Given a group of n distinct objects, the number of ways to choose r $\leq$ n of them is:

$$C_r^n = nCr = {n \choose x} = \frac{n(n-1)...(n-r+1)}{(n-r)!}=\frac{n!}{(n-r)!r!}$$

- The numbers ${n \choose x}$ are **binomial coefficients**
    - These appear in many places, such as the binomial theorem:
- For all x, y:

$$(x + y)^n = \sum_{r=0}^{n}{n \choose r}x^ry^{n-r}$$
